import json
import re
import requests
import urllib3
import time
from typing import List, Tuple
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# å¼•å…¥ OpenAI å…¼å®¹å®¢æˆ·ç«¯ (æ”¯æŒ DeepSeek å’Œ Azure)
from openai import AzureOpenAI, OpenAI
from src.config.loader import settings

# ç¦ç”¨ SSL è­¦å‘Š (å› ä¸ºæˆ‘ä»¬å¯èƒ½ç”¨ä»£ç†)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class LLMService:
    def __init__(self):
        # ==========================================
        # 1. åˆå§‹åŒ– HTTP Session (ç”¨äº Gemini REST API)
        # ==========================================
        self.session = requests.Session()
        
        # åº•å±‚è¿æ¥é‡è¯•é…ç½® (é’ˆå¯¹ Connection Reset / æ–­ç½‘)
        retry_strategy = Retry(
            total=3,
            backoff_factor=1, 
            status_forcelist=[500, 502, 504],
            allowed_methods=["POST"],
            raise_on_status=False
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)

        # ä»£ç†é…ç½®
        if settings.HTTP_PROXY or settings.HTTPS_PROXY:
            self.session.proxies = {
                "http": settings.HTTP_PROXY,
                "https": settings.HTTPS_PROXY
            }
            # print(f"ğŸŒ [LLMService] å·²å¯ç”¨ä»£ç†: {settings.HTTP_PROXY}")

        # ==========================================
        # 2. åˆå§‹åŒ– Azure OpenAI å®¢æˆ·ç«¯ (æ–°å¢)
        # ==========================================
        if all([settings.AZURE_OAI_KEY, settings.AZURE_OAI_ENDPOINT, settings.AZURE_OAI_DEPLOYMENT]):
            try:
                self._azure_client = AzureOpenAI(
                    api_key=settings.AZURE_OAI_KEY,
                    api_version=settings.AZURE_OAI_VERSION,
                    azure_endpoint=settings.AZURE_OAI_ENDPOINT,
                    timeout=60.0
                )
                print("[LLMService] Azure OpenAI client ready")
            except Exception as e:
                print(f"[Warning] [LLMService] Azure OpenAI åˆå§‹åŒ–å¤±è´¥: {e}")
                self._azure_client = None
        else:
            self._azure_client = None

        # ==========================================
        # 3. åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯ (ä½œä¸ºå¤‡ç”¨)
        # ==========================================
        if settings.DEEPSEEK_API_KEY:
            try:
                self._deepseek_client = OpenAI(
                    api_key=settings.DEEPSEEK_API_KEY,
                    base_url=settings.DEEPSEEK_BASE_URL,
                    timeout=60.0
                )
                print("[LLMService] DeepSeek client ready")
            except Exception as e:
                print(f"[Warning] [LLMService] DeepSeek åˆå§‹åŒ–å¤±è´¥: {e}")
                self._deepseek_client = None
        else:
            self._deepseek_client = None

    def call_llm(self, system_prompt: str, user_prompt: str) -> List[str]:
        """
        æ ¸å¿ƒ LLM è°ƒç”¨å‡½æ•°ï¼Œå®ç°äº†ä¸‰çº§å¤‡ç”¨é€»è¾‘ã€‚
        è¿”å›æ ¼å¼: [ "ç¬¦å·", "ç†ç”±" ]
        ä¾‹å¦‚: ["x", "HSç¼–ç ä¸å“åä¸ç¬¦"] æˆ– ["âˆš", "ç”³æŠ¥è¦ç´ å®Œæ•´"]
        """
        full_prompt = f"{system_prompt}\n\n{user_prompt}"

        # --- ç¬¬ä¸€çº§: å°è¯• Gemini (é€Ÿåº¦æœ€å¿«ï¼Œå…è´¹) ---
        if settings.GOOGLE_API_KEY:
            # print("INFO: [Attempt 1] Calling Gemini...")
            try:
                raw_text, model_name = self._call_gemini(system_prompt, user_prompt)
                return self._parse_json_response(raw_text)
            except Exception as e:
                print(f"[Warning] [LLM] Gemini è°ƒç”¨å¤±è´¥: {e}")
        else:
            print("INFO: [LLM] Google API Key æœªé…ç½®ï¼Œè·³è¿‡ Gemini")

        # --- ç¬¬äºŒçº§: å°è¯• Azure OpenAI (ä¼ä¸šçº§ç¨³å®š) ---
        if self._azure_client:
            print("INFO: [Attempt 2] Calling Azure OpenAI...")
            try:
                raw_text, model_name = self._call_azure_openai(full_prompt)
                return self._parse_json_response(raw_text)
            except Exception as e:
                print(f"[Warning] [LLM] Azure OpenAI è°ƒç”¨å¤±è´¥: {e}")
        
        # --- ç¬¬ä¸‰çº§: å°è¯• DeepSeek (æœ€å¼ºé€»è¾‘) ---
        if self._deepseek_client:
            print("INFO: [Attempt 3] Calling DeepSeek...")
            try:
                raw_text, model_name = self._call_deepseek(full_prompt)
                return self._parse_json_response(raw_text)
            except Exception as e:
                print(f"[Warning] [LLM] DeepSeek è°ƒç”¨å¤±è´¥: {e}")
        
        # --- æ‰€æœ‰æ¨¡å‹å‡å¤±è´¥ ---
        print("[Error] [LLM] ä¸¥é‡é”™è¯¯: æ‰€æœ‰å¯ç”¨æ¨¡å‹å‡è°ƒç”¨å¤±è´¥")
        return ["x", "ç³»ç»Ÿé”™è¯¯ï¼šæ‰€æœ‰AIæœåŠ¡å‡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIé…é¢ã€‚"]

    def _call_gemini(self, system_p: str, user_p: str) -> Tuple[str, str]:
        """
        è°ƒç”¨ Google Gemini REST API (ä¸ä¾èµ– google-generativeai åº“ï¼Œå‡å°‘ä¾èµ–å†²çª)
        """
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{settings.MODEL_NAME}:generateContent?key={settings.GOOGLE_API_KEY}"
        
        payload = {
            "contents": [{
                "parts": [{"text": f"{system_p}\n\n{user_p}"}]
            }],
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            ],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": 8192 
            }
        }
        
        # é€»è¾‘å±‚é‡è¯• (ä¸“é—¨é’ˆå¯¹ 503 Overloaded)
        max_retries = 2
        for attempt in range(max_retries + 1):
            response = self.session.post(api_url, json=payload, timeout=60, verify=False)
            
            # 503 æœåŠ¡ç¹å¿™ -> ç­‰å¾…é‡è¯•
            if response.status_code == 503:
                if attempt < max_retries:
                    time.sleep(2 * (attempt + 1))
                    continue
                else:
                    raise RuntimeError("Gemini 503 Overloaded (Max retries reached)")
            
            # å…¶ä»–é”™è¯¯
            if response.status_code != 200:
                raise RuntimeError(f"Gemini HTTP {response.status_code}: {response.text}")
            
            # æˆåŠŸè·å–
            result = response.json()
            if 'candidates' not in result:
                # å¯èƒ½æ˜¯è¢«å®‰å…¨ç­–ç•¥æ‹¦æˆª (PromptFeedback)
                if 'promptFeedback' in result:
                    raise RuntimeError(f"Gemini å®‰å…¨æ‹¦æˆª: {json.dumps(result['promptFeedback'])}")
                raise RuntimeError(f"Gemini è¿”å›æ ¼å¼å¼‚å¸¸: {json.dumps(result)}")
                
            candidate = result['candidates'][0]
            if 'content' not in candidate:
                finish_reason = candidate.get('finishReason', 'UNKNOWN')
                raise RuntimeError(f"Gemini ç”Ÿæˆä¸­æ–­: {finish_reason}")

            return candidate['content']['parts'][0]['text'], "Gemini"

    def _call_azure_openai(self, prompt: str) -> Tuple[str, str]:
        """
        è°ƒç”¨ Azure OpenAI
        """
        response = self._azure_client.chat.completions.create(
            model=settings.AZURE_OAI_DEPLOYMENT,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=8192,
            temperature=0.1
        )
        return response.choices[0].message.content, "Azure"

    def _call_deepseek(self, prompt: str) -> Tuple[str, str]:
        """
        è°ƒç”¨ DeepSeek
        """
        response = self._deepseek_client.chat.completions.create(
            model=settings.DEEPSEEK_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=8192,
            temperature=0.1
        )
        return response.choices[0].message.content, "DeepSeek"

    def _parse_json_response(self, raw_text: str) -> List[str]:
        """
        é²æ£’æ€§æå¼ºçš„ JSON è§£æå™¨
        ç›®æ ‡ï¼šä» AI çš„èƒ¡è¨€ä¹±è¯­ä¸­æå–å‡º ["ç¬¦å·", "ç†ç”±"]
        """
        clean_text = raw_text.strip()
        
        # 1. å°è¯•ç§»é™¤ Markdown ä»£ç å—æ ‡è®° (```json ... ```)
        # re.DOTALL è®© . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦
        match_code = re.search(r'```json\s*(.*?)\s*```', clean_text, re.DOTALL | re.IGNORECASE)
        if match_code:
            clean_text = match_code.group(1)
        else:
            # å°è¯•ç§»é™¤æ™®é€šä»£ç å— ``` ... ```
            clean_text = clean_text.replace("```", "")

        # 2. å°è¯•æå–æœ€å¤–å±‚çš„æ–¹æ‹¬å· [...]
        match_bracket = re.search(r'\[.*?\]', clean_text, re.DOTALL)
        if match_bracket:
            clean_text = match_bracket.group(0)

        # 3. å°è¯• JSON è§£æ
        try:
            parsed = json.loads(clean_text)
            if isinstance(parsed, list) and len(parsed) >= 2:
                # å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œé˜²æ­¢ AI è¿”å›æ•°å­—æˆ–å¸ƒå°”å€¼å¯¼è‡´å‰ç«¯æ¸²æŸ“å´©æºƒ
                return [str(parsed[0]), str(parsed[1])]
            return ["x", f"AIè¿”å›æ ¼å¼ä¸ç¬¦åˆäºŒå…ƒæ•°ç»„è¦æ±‚: {clean_text}"]
        except json.JSONDecodeError:
            # 4. JSON è§£æå¤±è´¥çš„å…œåº•ç­–ç•¥ (Heuristic Parsing)
            # å¦‚æœ AI å¾ˆè ¢ï¼Œç›´æ¥è¿”å›äº†ï¼š âˆš ç”³æŠ¥è¦ç´ å®Œæ•´
            lower_text = clean_text.lower()
            
            # åˆ¤æ–­é€šè¿‡
            if "âˆš" in clean_text or "pass" in lower_text or "true" in lower_text:
                # å»æ‰ä¸€äº›å¸¸è§çš„å¹²æ‰°å­—ç¬¦
                reason = clean_text.replace('"', '').replace("'", "").replace("[", "").replace("]", "").replace("âˆš", "").strip()
                return ["âˆš", reason or "é€šè¿‡"]
            
            # åˆ¤æ–­ä¸é€šè¿‡
            if "x" in clean_text.lower() or "fail" in lower_text or "false" in lower_text or "é£é™©" in clean_text:
                reason = clean_text.replace('"', '').replace("'", "").replace("[", "").replace("]", "").replace("x", "").replace("X", "").strip()
                return ["x", reason or "å­˜åœ¨é£é™©"]

            return ["x", f"æ— æ³•è§£æAIå“åº”: {clean_text}"]
        except Exception as e:
            return ["x", f"è§£æè¿‡ç¨‹å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"]

# --- å•å…ƒæµ‹è¯• ---
if __name__ == "__main__":
    # ç®€å•çš„è¿è¡Œæµ‹è¯•
    service = LLMService()
    print("æ­£åœ¨æµ‹è¯• LLM è¿æ¥...")
    res = service.call_llm("ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ã€‚", "è¯·è¿”å›jsonæ ¼å¼ï¼š[\"âˆš\", \"æµ‹è¯•æˆåŠŸ\"]")
    print(f"æµ‹è¯•ç»“æœ: {res}")