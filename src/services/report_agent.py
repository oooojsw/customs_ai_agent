import json
import asyncio
import httpx
import random
import re
from typing import List, AsyncGenerator, Set
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from pathlib import Path

# å¯¼å…¥é…ç½®
from src.config.loader import settings

# çŸ¥è¯†åº“å®¹é”™å¯¼å…¥
try:
    from src.services.knowledge_base import KnowledgeBase
except ImportError:
    KnowledgeBase = None

class ComplianceReporter:
    def __init__(self):
        print("ğŸ“‘ [System] åˆå§‹åŒ–åŒæ¨¡ç ”åˆ¤å¼•æ“ (Hybrid Deep Research Engine)...")
        
        # 1. ç½‘ç»œå±‚é…ç½®
        proxy_url = settings.HTTP_PROXY
        async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
        self.async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)

        # 2. LLM åˆå§‹åŒ– (R1 é€»è¾‘æœ€å¼º)
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL,
            temperature=0.3, 
            http_async_client=self.async_client,
            streaming=True,
            model_kwargs={"stream": True}
        )

        # 3. çŸ¥è¯†åº“æ£€ç´¢å™¨
        self.kb = None
        if KnowledgeBase:
            try:
                self.kb = KnowledgeBase()
            except Exception as e:
                print(f"âš ï¸ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")

        # 4. åŠ è½½åŒæ¨¡ SOP
        self.sop_customs = self._load_specific_sop("sop_process.txt", "æ ‡å‡†æµ·å…³åˆè§„å®¡æŸ¥SOP")
        self.sop_research = self._load_specific_sop("sop_deep_research.txt", "é€šç”¨æ·±åº¦ç ”åˆ¤SOP")

    def _load_specific_sop(self, filename: str, default_text: str) -> str:
        try:
            base_dir = Path(__file__).resolve().parent.parent.parent
            sop_path = base_dir / "config" / filename
            if sop_path.exists():
                with open(sop_path, "r", encoding="utf-8") as f:
                    return f.read()
            return default_text
        except:
            return default_text

    def _detect_mode(self, text: str) -> str:
        """
        ç®€å•é«˜æ•ˆçš„è§„åˆ™è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦ä¸ºæŠ¥å…³å•
        """
        # å…³é”®è¯å‘½ä¸­ 2 ä¸ªä»¥ä¸Šå³è§†ä¸ºæŠ¥å…³å•
        keywords = ["æŠ¥å…³å•", "HSç¼–ç ", "ç”³æŠ¥è¦ç´ ", "å¢ƒå†…æ”¶è´§äºº", "æˆäº¤æ–¹å¼", "æè¿å•å·", "æ¯›é‡", "å‡€é‡"]
        hit_count = sum(1 for k in keywords if k in text)
        
        if hit_count >= 2:
            return "CUSTOMS"
        return "RESEARCH"

    async def generate_stream(self, input_text: str) -> AsyncGenerator[str, None]:
        """
        æ™ºèƒ½åŒæ¨¡ç”Ÿæˆæµ (ä¼˜åŒ–ç‰ˆï¼šæœ€åä¸€ç« è·³è¿‡ RAG)
        """
        # 1. è·¯ç”±åˆ¤æ–­
        mode = self._detect_mode(input_text)
        
        if mode == "CUSTOMS":
            active_sop = self.sop_customs
            role_desc = "æµ·å…³é«˜çº§æŸ¥éªŒä¸“å®¶"
            task_desc = "è¿›è¡Œè¿›å‡ºå£åˆè§„æ€§å®¡æŸ¥"
            yield self._sse("thought", "ğŸ” æ£€æµ‹åˆ°æŠ¥å…³å•æ®ï¼Œå·²åˆ‡æ¢è‡³ã€åˆè§„å®¡è®¡æ¨¡å¼ã€‘...")
        else:
            active_sop = self.sop_research
            role_desc = "æ·±åº¦æ¡£æ¡ˆåˆ†æå¸ˆ"
            task_desc = "è¿›è¡Œæœ¬åœ°çŸ¥è¯†åº“æ·±åº¦æŒ–æ˜ä¸ç ”åˆ¤"
            yield self._sse("thought", "ğŸ§  æ£€æµ‹åˆ°é€šç”¨é—®é¢˜ï¼Œå·²åˆ‡æ¢è‡³ã€æ·±åº¦ç ”åˆ¤æ¨¡å¼ (DeepResearch)ã€‘...")
        
        await asyncio.sleep(0.5)

        # åˆå§‹åŒ–çŠ¶æ€
        state = {
            "topic": input_text,
            "mode": mode,
            "toc": [],
            "notebook": [],
            "used_doc_hashes": set(), 
            "full_report_text": "",
        }

        try:
            # ==========================================
            # é˜¶æ®µ 1: åŠ¨æ€è§„åˆ’ (Planning)
            # ==========================================
            yield self._sse("thought", f"æ­£åœ¨åŸºäº[{role_desc}]è§†è§’æ„å»ºå¤§çº²...")
            
            toc_list = await self._generate_toc(input_text, mode, active_sop)
            state["toc"] = toc_list
            yield self._sse("toc", toc_list)
            
            # ==========================================
            # é˜¶æ®µ 2: ç« èŠ‚å¾ªç¯ (Section Loop)
            # ==========================================
            for i, section_title in enumerate(toc_list):
                # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€åä¸€ç« 
                is_last_chapter = (i == len(toc_list) - 1)
                
                yield self._sse("step_start", {"index": i, "title": section_title})
                
                section_search_history = []
                section_notes = []

                # --- åˆ†æ”¯é€»è¾‘ï¼šå¦‚æœæ˜¯æœ€åä¸€ç« ï¼Œè·³è¿‡ RAG ---
                if is_last_chapter:
                    yield self._sse("thought", "æ­£åœ¨å›é¡¾å…¨æ–‡ï¼Œè¿›è¡Œé€»è¾‘æ”¶æŸä¸æœ€ç»ˆç ”åˆ¤ (Skip RAG)...")
                    # æ¨¡æ‹Ÿä¸€ç‚¹æ€è€ƒæ—¶é—´ï¼Œè®©å‰ç«¯ä½“éªŒæ›´å¥½
                    await asyncio.sleep(1.5)
                    section_notes.append("ï¼ˆæœ¬ç« ä¸ºæ€»ç»“ç« èŠ‚ï¼ŒåŸºäºå‰æ–‡æ‰€æœ‰åˆ†æå¾—å‡ºç»“è®ºï¼Œä¸å†æ£€ç´¢æ–°è¯æ®ï¼‰")
                
                else:
                    # --- æ™®é€šç« èŠ‚ï¼šæ­£å¸¸è¿›è¡Œ RAG æŒ–æ˜ ---
                    research_rounds = 2 if mode == "CUSTOMS" else 3
                    
                    for round_idx in range(1, research_rounds + 1):
                        # ... (è¿™é‡Œä¿æŒåŸæœ‰çš„ RAG é€»è¾‘ä¸å˜) ...
                        previous_context = state["full_report_text"][-800:] if state["full_report_text"] else "ï¼ˆé¦–ç« ï¼‰"
                        
                        if mode == "CUSTOMS":
                            strategy_instruction = "è¯·æå–å½“å‰ç« èŠ‚éœ€è¦çš„æ³•è§„ä¾æ®ã€HSç¼–ç è§„åˆ™æˆ–ç›‘ç®¡è¦æ±‚ä½œä¸ºæ£€ç´¢è¯ã€‚"
                        else:
                            strategy_instruction = "è¯·æ€è€ƒä¸ºäº†å®Œå–„æœ¬ç« è®ºç‚¹ï¼Œè¿˜éœ€è¦åœ¨æœ¬åœ°æ–‡æ¡£ä¸­æŒ–æ˜ä»€ä¹ˆå…·ä½“çš„è¯æ®æˆ–ç»†èŠ‚ï¼Ÿ"

                        strategy_prompt = f"""
ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚

ã€âš ï¸ æ ¸å¿ƒè¦æ±‚ã€‘
è¯·æå–ä¸€ä¸ªç®€çŸ­çš„æ£€ç´¢å…³é”®è¯ï¼ˆ2-6ä¸ªè¯ï¼‰ï¼Œç”¨äºåœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸å…³æ³•è§„æˆ–æŠ€æœ¯èµ„æ–™ã€‚

ã€é™åˆ¶æ¡ä»¶ã€‘
1. **ä¸¥ç¦è¾“å‡ºåˆ†æè¿‡ç¨‹**ï¼Œç›´æ¥è¾“å‡ºå…³é”®è¯
2. å…³é”®è¯é•¿åº¦ï¼š2-6ä¸ªè¯
3. ä¸è¦è¾“å‡ºå®Œæ•´å¥å­æˆ–æ®µè½
4. åªè¾“å‡ºå…³é”®è¯ï¼Œä¸è¦å¼•å·ã€ä¸è¦æ ‡ç‚¹

ã€å‚è€ƒç¤ºä¾‹ã€‘
âœ… æ­£ç¡®ï¼šHSç¼–ç 8536 å½’ç±»è§„åˆ™
âœ… æ­£ç¡®ï¼šé”‚ç”µæ±  è”åˆå›½å±é™©å“åˆ†ç±»
âœ… æ­£ç¡®ï¼šè´¸æ˜“ç®¡åˆ¶ å‡ºå£è®¸å¯è¯
âŒ é”™è¯¯ï¼šä¸ºäº†æ˜ç¡®è¯¥äº§å“çš„å½’ç±»ï¼Œæˆ‘éœ€è¦æŸ¥æ‰¾...
âŒ é”™è¯¯ï¼šè¯¥äº§å“çš„ç‰©ç†æ¥å£ç»†èŠ‚åŒ…æ‹¬...

ã€å½“å‰ä¸Šä¸‹æ–‡ã€‘
ç« èŠ‚ï¼š{section_title}
å‰æ–‡ï¼š{previous_context[:200]}
"""
                        q_res = await self.llm.ainvoke([HumanMessage(content=strategy_prompt)])
                        # æ¸…ç†è¾“å‡ºï¼Œåªå–ç¬¬ä¸€è¡Œï¼Œå»é™¤æ ‡ç‚¹å’Œå¼•å·
                        query = q_res.content.strip().split('\n')[0].strip('"\'')
                        # å»é™¤å¸¸è§ä¸­æ–‡æ ‡ç‚¹
                        for char in 'ã€‚ï¼Œã€ï¼Ÿï¼':
                            query = query.strip(char)
                        section_search_history.append(query)
                        
                        yield self._sse("thought", f"[Round {round_idx}] æ­£åœ¨çŸ¥è¯†åº“æ¯”å¯¹ï¼š'{query}'")
                        yield self._sse("rag_search", {"query": query})
                        
                        # æ‰§è¡Œæ£€ç´¢ï¼ˆä½¿ç”¨çœŸå®ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰
                        snippet = ""
                        score = 0.0
                        filename = "LocalDB"

                        if self.kb:
                            try:
                                # è°ƒç”¨æ–°çš„å¸¦åˆ†æ•°æ£€ç´¢æ–¹æ³•
                                results = await self.kb.search_with_score(query, k=6)

                                for doc, similarity in results:
                                    doc_hash = hash(doc.page_content[:30])
                                    if doc_hash not in state["used_doc_hashes"]:
                                        snippet = doc.page_content
                                        filename = Path(doc.metadata.get("source", "unknown")).name
                                        score = similarity  # ä½¿ç”¨çœŸå®çš„ç›¸ä¼¼åº¦ç™¾åˆ†æ¯” (0-100)
                                        state["used_doc_hashes"].add(doc_hash)
                                        break

                                # å¦‚æœæ‰€æœ‰æ–‡æ¡£éƒ½ç”¨è¿‡äº†ï¼Œå–ç¬¬ä¸€ä¸ªä½œä¸ºåå¤‡
                                if not snippet and results:
                                    snippet = results[0][0].page_content
                                    score = results[0][1] * 0.8  # ç¨å¾®é™æƒï¼Œå› ä¸ºæ˜¯é‡å¤ä½¿ç”¨

                            except Exception as e:
                                print(f"æ£€ç´¢é”™: {e}")
                                import traceback
                                traceback.print_exc()

                        if not snippet:
                            snippet = "ï¼ˆæœªåœ¨æœ¬åœ°çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›´æ¥å¯¹åº”æ¡æ¬¾ï¼Œéœ€ä¾æ®é€šç”¨ä¸“ä¸šçŸ¥è¯†åˆ¤æ–­ï¼‰"
                            score = 0.0

                        yield self._sse("rag_result", {
                            "filename": filename,
                            "score": float(score),  # ç¡®ä¿ JSON å¯åºåˆ—åŒ–
                            "snippet": snippet[:100] + "..."
                        })

                        note_content = f"å…³é”®è¯[{query}] -> å‘ç°ï¼š{snippet}"
                        section_notes.append(note_content)
                        state["notebook"].append(note_content)
                        await asyncio.sleep(0.5)

                # --- å­å¾ªç¯ç»“æŸï¼Œæ’°å†™æ­£æ–‡ ---
                
                # åŠ¨æ€è°ƒæ•´å†™ä½œ Prompt
                previous_context_full = state["full_report_text"][-1500:] if state["full_report_text"] else "æ— "
                
                if is_last_chapter:
                    yield self._sse("thought", "æ­£åœ¨ç»¼åˆå‰æ–‡æ‰€æœ‰è§‚ç‚¹ï¼Œç”Ÿæˆæœ€ç»ˆç»“è®º...")
                    instruction_special = "è¿™æ˜¯æŠ¥å‘Šçš„ã€æœ€ç»ˆç« ã€‘ã€‚è¯·ä¸è¦å¼•å…¥æ–°çš„äº‹å®è¯æ®ï¼Œè€Œæ˜¯å¯¹ã€å‰æ–‡è„‰ç»œã€‘ä¸­æåˆ°çš„æ ¸å¿ƒé—®é¢˜ã€é£é™©ç‚¹æˆ–å‘ç°è¿›è¡Œé«˜åº¦æ¦‚æ‹¬å’Œæ€»ç»“ã€‚ç»™å‡ºæ˜ç¡®çš„ä¸‹ä¸€æ­¥å»ºè®®ã€‚"
                else:
                    yield self._sse("thought", "è¯æ®é“¾é—­åˆï¼Œæ­£åœ¨ç”Ÿæˆä¸“ä¸šåˆ†ææŠ¥å‘Š...")
                    instruction_special = f"è¯·åŸºäºã€æ ¸å¿ƒè¯æ®ã€‘æ’°å†™æœ¬ç« ã€‚{role_desc}é£æ ¼ã€‚æ‰¿æ¥å‰æ–‡ï¼Œé€»è¾‘é€šé¡ºã€‚"

                write_prompt = f"""
ä½ æ˜¯ä¸€å{role_desc}ã€‚è¯·æ’°å†™ã€Š{section_title}ã€‹ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
{task_desc}

ã€å‰æ–‡è„‰ç»œ (åŸºäºæ­¤è¿›è¡Œè¡”æ¥/æ€»ç»“)ã€‘
...{previous_context_full}

ã€æ ¸å¿ƒè¯æ®ã€‘
{json.dumps(section_notes, ensure_ascii=False)}

ã€åŸå§‹è¾“å…¥ã€‘
{input_text}

ã€å†™ä½œæŒ‡ä»¤ã€‘
1. {instruction_special}
2. ç›´æ¥è¾“å‡º Markdown æ­£æ–‡ã€‚

ã€âš ï¸ æ ¼å¼è¦æ±‚ - é‡è¦ã€‘
- **ä¸¥ç¦åœ¨æ­£æ–‡å¼€å¤´é‡å¤ç« èŠ‚æ ‡é¢˜**ï¼ˆå¦‚ "## 2. ä»·æ ¼å®¡æŸ¥"ï¼‰ï¼Œå› ä¸ºç³»ç»Ÿå·²ç»è‡ªåŠ¨æ˜¾ç¤ºäº†æ ‡é¢˜
- **ç›´æ¥ä»æ­£æ–‡ç¬¬ä¸€æ®µå¼€å§‹å†™**ï¼Œä¾‹å¦‚ï¼š

âŒ é”™è¯¯ç¤ºä¾‹ï¼š
## 2. ä»·æ ¼çœŸå®æ€§ä¸é€»è¾‘å®¡æŸ¥
æ‰¿æ¥å‰æ–‡å½’ç±»å¤æ ¸ç»“è®º...

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
æ‰¿æ¥å‰æ–‡å½’ç±»å¤æ ¸ç»“è®ºï¼ŒHSç¼–ç 8479.8962çš„é€‚ç”¨æ€§è™½åŸºæœ¬æˆç«‹ï¼Œä½†ç”³æŠ¥è¦ç´ çš„ç®€åŒ–æè¿°...

"""
                current_section_content = ""
                async for chunk in self.llm.astream([HumanMessage(content=write_prompt)]):
                    if chunk.content:
                        current_section_content += chunk.content
                        yield self._sse("report_chunk", chunk.content)
                
                state["full_report_text"] += f"\n\n## {section_title}\n\n{current_section_content}"
                yield self._sse("step_done", {"index": i})

            # ==========================================
            # é˜¶æ®µ 3: å®Œç»“
            # ==========================================
            yield self._sse("thought", "æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚")
            yield self._sse("done", {})

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            yield self._sse("error", str(e))

    async def _generate_toc(self, topic: str, mode: str, sop: str) -> List[str]:
        """
        åŒæ¨¡ç›®å½•ç”Ÿæˆå™¨ (å¸¦æ¸…æ´—åŠŸèƒ½ï¼Œä¿®å¤ä¹±ç é—®é¢˜)
        """
        if mode == "CUSTOMS":
            advice_structure = """
            å»ºè®®åŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼ˆè¯·åªè¿”å›æ ‡é¢˜å­—ç¬¦ä¸²ï¼‰ï¼š
            1. ç”³æŠ¥è¦ç´ ä¸å½’ç±»å¤æ ¸
            2. ä»·æ ¼çœŸå®æ€§ä¸é€»è¾‘å®¡æŸ¥
            3. è´¸æ˜“ç®¡åˆ¶ä¸å‡†å…¥é£é™©
            4. ç»¼åˆç»“è®ºä¸æ•´æ”¹å»ºè®®
            """
        else:
            advice_structure = """
            å»ºè®®åŒ…å« 4-6 ä¸ªç« èŠ‚ï¼ˆè¯·åªè¿”å›æ ‡é¢˜å­—ç¬¦ä¸²ï¼‰ï¼š
            - ç¬¬ä¸€ç« å¿…é¡»æ˜¯èƒŒæ™¯/ç°çŠ¶æ¦‚è¿°
            - ä¸­é—´ç« èŠ‚æŒ‰ä¸»é¢˜é€»è¾‘å±•å¼€
            - æœ€åä¸€ç« æ˜¯ç»“è®ºä¸è¯æ®ç¼ºå£è¯´æ˜
            """

        prompt = f"""
ä½ æ˜¯ä¸€åé«˜çº§åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥å’ŒSOPè®¾è®¡ç›®å½•ã€‚

ã€ç”¨æˆ·è¾“å…¥ã€‘
{topic}

ã€SOPã€‘
{sop}

ã€ç»“æ„å»ºè®®ã€‘
{advice_structure}

ã€ä¸¥æ ¼æ ¼å¼è¦æ±‚ã€‘
1. å¿…é¡»è¿”å›ä¸€ä¸ªçº¯ JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¾‹å¦‚ï¼š["1. ç« èŠ‚åç§°", "2. ç« èŠ‚åç§°"]ã€‚
2. ä¸¥ç¦è¿”å›å¯¹è±¡æˆ–å­—å…¸ï¼ˆä¸è¦ä½¿ç”¨ key-value ç»“æ„ï¼‰ã€‚
3. ä¸è¦ Markdown æ ‡è®°ã€‚
"""
        try:
            res = await self.llm.ainvoke([HumanMessage(content=prompt)])
            # 1. æ¸…æ´— Markdown æ ‡è®°
            text = res.content.replace("```json", "").replace("```", "").strip()
            
            # 2. è§£æ JSON
            parsed = json.loads(text)
            
            # 3. ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶æ‰å¹³åŒ–å¤„ç†
            # æ— è®º LLM è¿”å›çš„æ˜¯ [{"title": "A"}, {"title": "B"}] è¿˜æ˜¯ ["A", "B"]
            # æˆ‘ä»¬éƒ½æŠŠå®ƒç»Ÿä¸€è½¬æˆ ["1. A", "2. B"]
            clean_toc = []
            
            if isinstance(parsed, list):
                for idx, item in enumerate(parsed):
                    title = ""
                    if isinstance(item, str):
                        title = item
                    elif isinstance(item, dict):
                        # å¦‚æœæ¨¡å‹ä¸å¬è¯è¿”å›äº†å¯¹è±¡ï¼Œå°è¯•æå– value ä¸­çœ‹èµ·æ¥åƒæ ‡é¢˜çš„å­—æ®µ
                        # ä¼˜å…ˆæ‰¾ 'title', 'name', 'chapter'ï¼Œæ‰¾ä¸åˆ°å°±å–ç¬¬ä¸€ä¸ª value
                        for key in ['title', 'chapterTitle', 'chapter_name', 'name', 'header']:
                            if key in item:
                                title = str(item[key])
                                break
                        if not title and item.values():
                            title = str(list(item.values())[0])
                    
                    # ç§»é™¤å·²æœ‰çš„åºå·ï¼Œé‡æ–°ç¼–å·ï¼Œä¿è¯å‰ç«¯æ˜¾ç¤ºæ•´é½
                    if title:
                        # å»æ‰å¼€å¤´çš„ "1.", "1 ", "Chapter 1" ç­‰
                        clean_title = re.sub(r'^(\d+\.|Chapter\s*\d+|ç¬¬.+ç« )\s*', '', title).strip()
                        clean_toc.append(f"{idx + 1}. {clean_title}")
            
            if not clean_toc:
                raise ValueError("Parsed TOC is empty")
                
            return clean_toc

        except Exception as e:
            print(f"âŒ ç›®å½•ç”Ÿæˆè§£æå¤±è´¥: {e}, å¯ç”¨å…œåº•ç­–ç•¥")
            # å…œåº•ç›®å½•
            if mode == "CUSTOMS":
                return ["1. ç”³æŠ¥è¦ç´ å¤æ ¸", "2. ä»·æ ¼é€»è¾‘åˆ†æ", "3. ç›‘ç®¡è¯ä»¶ç­›æŸ¥", "4. ç»“è®ºå»ºè®®"]
            return ["1. èƒŒæ™¯æ¦‚è¿°", "2. æ ¸å¿ƒäº‹å®æ¢³ç†", "3. æ·±åº¦å…³è”åˆ†æ", "4. ç»“è®ºä¸å±•æœ›"]

    def _sse(self, type_str, payload):
        return f"data: {json.dumps({'type': type_str, 'payload': payload}, ensure_ascii=False)}\n\n"