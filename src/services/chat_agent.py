import os
import httpx
import asyncio
import json
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import Tool
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.runnables import RunnableConfig

# å¼•å…¥ create_react_agent (LangGraph æ¨èæ–¹å¼)
from langgraph.prebuilt import create_react_agent

from src.config.loader import settings

# --- ç¯å¢ƒé…ç½® ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HUB_DISABLE_SSL_VERIFY'] = '1'
os.environ['CURL_CA_BUNDLE'] = ''

# çŸ¥è¯†åº“å®¹é”™
try:
    from src.services.knowledge_base import KnowledgeBase
except ImportError:
    KnowledgeBase = None

MEMORY = InMemorySaver()

class CustomsChatAgent:
    def __init__(self):
        print("ğŸ”— [System] åˆå§‹åŒ– Agent (DeepSeek æ·±åº¦ä¼˜åŒ–ç‰ˆ)...")
        
        # 1. ç½‘ç»œé…ç½®
        proxy_url = settings.HTTP_PROXY if hasattr(settings, 'HTTP_PROXY') and settings.HTTP_PROXY else None
        
        if proxy_url:
            async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
            async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)
        else:
            async_client = httpx.AsyncClient(verify=False, timeout=120.0)

        # 2. LLM åˆå§‹åŒ– (ä¸¥æ ¼éµå¾ª DeepSeek æ–‡æ¡£)
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL,
            temperature=0.3,
            http_async_client=async_client,
            streaming=True, # å¿…é¡»å¼€å¯
            model_kwargs={
                # æ˜¾å¼å¼€å¯æµå¼ï¼Œé˜²æ­¢è¢« Agent è¦†ç›–
                "stream": True,
                # ã€å…³é”®ã€‘ç¦ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ï¼ŒDeepSeek æ–‡æ¡£è™½æœªæ˜è¯´ï¼Œä½†å®æµ‹èƒ½å‡å°‘æœåŠ¡ç«¯ç¼“å†²
                "parallel_tool_calls": False,
                # å‡å°‘ä¸å¿…è¦çš„æ•°æ®ä¼ è¾“
                "stream_options": {"include_usage": False} 
            }
        )

        # 3. å·¥å…·
        tools = []
        self.retriever = None
        if KnowledgeBase:
            try:
                self.kb = KnowledgeBase()
                self.retriever = self.kb.get_retriever()
                
                def retrieve_docs(query: str) -> str:
                    if not self.retriever: return "çŸ¥è¯†åº“ä¸å¯ç”¨ã€‚"
                    try:
                        docs = self.retriever.invoke(query)
                        return "\n\n".join([doc.page_content for doc in docs]) if docs else "æœªæ‰¾åˆ°ã€‚"
                    except Exception as e:
                        return f"æ£€ç´¢é”™: {e}"

                tools.append(Tool(
                    name="search_customs_regulations",
                    func=retrieve_docs,
                    description="æŸ¥è¯¢æµ·å…³æ³•è§„ã€æ”¿ç­–ã€HSç¼–ç æˆ–æŠ¥å…³æµç¨‹ã€‚"
                ))
            except: pass
        
        # 4. Agent æ„å»º (ä½¿ç”¨ LangGraph)
        self.agent = create_react_agent(
            model=self.llm,
            tools=tools,
            # prompt="ä½ æ˜¯ä¸€åæµ·å…³ä¸“å®¶...", # æ–°ç‰ˆ LangGraph è¿™é‡Œç”¨ state_modifier
            checkpointer=MEMORY,
        )

    async def chat_stream(self, user_input: str, session_id: str = "default_session"):
        """
        ä½¿ç”¨ astream_events ç›‘å¬åº•å±‚ LLM äº‹ä»¶ï¼Œç»•è¿‡ Agent çš„ç¼“å†²
        """
        print(f"\nğŸ‘‰ [Request] {user_input}")
        yield f"data: {{\"type\": \"thinking\", \"content\": \"è¿æ¥å»ºç«‹...\"}}\n\n"
        
        config = {"configurable": {"thread_id": session_id}}
        has_sent_content = False

        try:
            # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨ astream_events (v2)
            # å®ƒå¯ä»¥ç©¿é€ Graph çš„å±‚çº§ï¼Œç›´æ¥æ•è·æœ€åº•å±‚çš„ on_chat_model_stream äº‹ä»¶
            # æ— è®º Agent é€»è¾‘æ€ä¹ˆå¡ï¼Œåªè¦ LLM åå­—ï¼Œè¿™é‡Œå°±èƒ½æ”¶åˆ°ï¼
            async for event in self.agent.astream_events(
                {"messages": [HumanMessage(content=user_input)]},
                config=config,
                version="v2"
            ):
                event_type = event["event"]
                
                # 1. ç›‘å¬ LLM çš„æµå¼è¾“å‡º (æœ€æ ¸å¿ƒçš„éƒ¨åˆ†)
                if event_type == "on_chat_model_stream":
                    chunk = event["data"]["chunk"]
                    
                    # A. æ•è·æ­£æ–‡å†…å®¹ (Content)
                    if chunk.content:
                        has_sent_content = True
                        safe_content = chunk.content.replace("\n", "\\n").replace('"', '\\"')
                        yield f"data: {{\"type\": \"answer\", \"content\": \"{safe_content}\"}}\n\n"
                    
                    # B. æ•è· DeepSeek çš„æ€è€ƒè¿‡ç¨‹ (Reasoning)
                    # DeepSeek çš„ thinking é€šå¸¸åœ¨ additional_kwargs é‡Œ
                    reasoning = chunk.additional_kwargs.get('reasoning_content', '')
                    if reasoning:
                        safe_reason = reasoning.replace("\n", "\\n").replace('"', '\\"')
                        yield f"data: {{\"type\": \"thinking\", \"content\": \"{safe_reason}\"}}\n\n"
                    
                    # æçŸ­ä¼‘çœ ï¼Œç¡®ä¿ I/O ä¸é˜»å¡
                    await asyncio.sleep(0)

                # 2. ç›‘å¬å·¥å…·å¼€å§‹è°ƒç”¨ (ç”¨äºå‰ç«¯æ˜¾ç¤ºçŠ¶æ€)
                elif event_type == "on_tool_start":
                    tool_name = event["name"]
                    yield f"data: {{\"type\": \"thinking\", \"content\": \"æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}...\"}}\n\n"

                # 3. ç›‘å¬å·¥å…·ç»“æŸ
                elif event_type == "on_tool_end":
                    yield f"data: {{\"type\": \"thinking\", \"content\": \"å·¥å…·è°ƒç”¨å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›å¤...\"}}\n\n"

            # ä¿åº•é€»è¾‘ (å¦‚æœäº‹ä»¶æµæ²¡æœ‰æ•è·åˆ°ä»»ä½•å†…å®¹)
            if not has_sent_content:
                print("âš ï¸ äº‹ä»¶æµæœªæ•è·å†…å®¹ï¼Œå°è¯•è¯»å–æœ€ç»ˆçŠ¶æ€...")
                state = await self.agent.aget_state(config)
                if state.values.get("messages"):
                    last = state.values["messages"][-1]
                    if isinstance(last, AIMessage) and last.content:
                        safe = last.content.replace("\n", "\\n").replace('"', '\\"')
                        yield f"data: {{\"type\": \"answer\", \"content\": \"{safe}\"}}\n\n"

        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {{\"type\": \"error\", \"content\": \"{str(e)}\"}}\n\n"