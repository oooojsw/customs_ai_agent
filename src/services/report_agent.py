import json
import asyncio
import httpx
import random
import re
from typing import List, AsyncGenerator, Set
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from pathlib import Path

# å¯¼å…¥é…ç½®
from src.config.loader import settings

# çŸ¥è¯†åº“å®¹é”™å¯¼å…¥
try:
    from src.services.knowledge_base import KnowledgeBase
    KB_AVAILABLE = True
except ImportError:
    KnowledgeBase = None
    KB_AVAILABLE = False
    print("âš ï¸ [System] KnowledgeBase æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä»¥æ— çŸ¥è¯†åº“æ¨¡å¼è¿è¡Œ")

class ComplianceReporter:
    def __init__(self):
        print("ğŸ“‘ [System] åˆå§‹åŒ– ComplianceReporter...")
        
        # 1. ç½‘ç»œå±‚é…ç½®
        proxy_url = settings.HTTP_PROXY
        # å¼ºåˆ¶å…³é—­ SSL éªŒè¯
        if proxy_url:
            async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
            self.async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)
        else:
            self.async_client = httpx.AsyncClient(verify=False, timeout=120.0)

        # 2. LLM åˆå§‹åŒ–
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL,
            temperature=0.3,
            http_async_client=self.async_client,
            streaming=True,
            model_kwargs={"stream": True}
        )

        # 3. çŸ¥è¯†åº“æ£€ç´¢å™¨
        self.kb = None
        if KB_AVAILABLE:
            try:
                self.kb = KnowledgeBase()
            except Exception as e:
                print(f"   âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ (è·³è¿‡): {e}")

        # 4. åŠ è½½åŒæ¨¡ SOP
        self.sop_customs = self._load_specific_sop("sop_process.txt", "æ ‡å‡†æµ·å…³åˆè§„å®¡æŸ¥SOP")
        self.sop_research = self._load_specific_sop("sop_deep_research.txt", "é€šç”¨æ·±åº¦ç ”åˆ¤SOP")

    def _load_specific_sop(self, filename: str, default_text: str) -> str:
        try:
            base_dir = Path(__file__).resolve().parent.parent.parent
            sop_path = base_dir / "config" / filename
            if sop_path.exists():
                with open(sop_path, "r", encoding="utf-8") as f:
                    return f.read()
            return default_text
        except:
            return default_text

    def _detect_mode(self, text: str) -> str:
        keywords = ["æŠ¥å…³å•", "HSç¼–ç ", "ç”³æŠ¥è¦ç´ ", "å¢ƒå†…æ”¶è´§äºº", "æˆäº¤æ–¹å¼", "æè¿å•å·", "æ¯›é‡", "å‡€é‡"]
        hit_count = sum(1 for k in keywords if k in text)
        return "CUSTOMS" if hit_count >= 2 else "RESEARCH"

    async def generate_stream(self, input_text: str, language: str = "zh") -> AsyncGenerator[str, None]:
        """
        æ ¸å¿ƒç”Ÿæˆæµ
        """
        # 0. ç«‹å³æ¡æ‰‹
        engine_start = self._get_ui_text("engine_start", language)
        yield self._sse("thought", f"ğŸš€ {engine_start}")
        await asyncio.sleep(0.1)

        # 1. è·¯ç”±åˆ¤æ–­
        mode = self._detect_mode(input_text)
        
        if mode == "CUSTOMS":
            active_sop = self.sop_customs
            role_desc = self._get_ui_text("role_customs", language)
            task_desc = self._get_ui_text("task_customs", language)
            yield self._sse("thought", f"ğŸ” {self._get_ui_text('audit_mode', language)}")
        else:
            active_sop = self.sop_research
            role_desc = self._get_ui_text("role_research", language)
            task_desc = self._get_ui_text("task_research", language)
            yield self._sse("thought", f"ğŸ§  {self._get_ui_text('research_mode', language)}")
        
        state = {
            "topic": input_text,
            "mode": mode,
            "toc": [],
            "notebook": [],
            "used_doc_hashes": set(), 
            "full_report_text": "",
        }

        try:
            # ==========================================
            # é˜¶æ®µ 1: åŠ¨æ€è§„åˆ’
            # ==========================================
            building_outline = self._get_ui_text("building_outline", language)
            yield self._sse("thought", f"{building_outline}[{role_desc}]è§†è§’æ„å»ºå¤§çº²...")

            # ç¡®ä¿è¿™é‡Œä¼ äº† 4 ä¸ªå‚æ•°ï¼ˆåŒ…æ‹¬ languageï¼‰
            toc_list = await self._generate_toc(input_text, mode, active_sop, language)

            state["toc"] = toc_list
            yield self._sse("toc", toc_list)

            # ==========================================
            # é˜¶æ®µ 2: ç« èŠ‚å¾ªç¯
            # ==========================================
            for i, section_title in enumerate(toc_list):
                is_last_chapter = (i == len(toc_list) - 1)
                yield self._sse("step_start", {"index": i, "title": section_title})

                section_search_history = []
                section_notes = []

                if is_last_chapter:
                    reviewing_full_text = self._get_ui_text("reviewing_full_text", language)
                    yield self._sse("thought", f"{reviewing_full_text}...")
                    await asyncio.sleep(1.0)
                else:
                    research_rounds = 2 if mode == "CUSTOMS" else 3
                    for round_idx in range(1, research_rounds + 1):
                        previous_context = state["full_report_text"][-800:] if state["full_report_text"] else "ï¼ˆé¦–ç« ï¼‰"

                        # æ”¹è¿›çš„æœç´¢ç­–ç•¥ï¼šç¡®ä¿æ¯è½®æœç´¢ä¸åŒè§’åº¦
                        if round_idx == 1:
                            # ç¬¬ä¸€è½®ï¼šä»ç« èŠ‚æ ‡é¢˜ç›´æ¥æå–å…³é”®è¯
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚è¯·ç”Ÿæˆä¸€ä¸ªç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ï¼Œç›´æ¥ä»ç« èŠ‚æ ‡é¢˜ä¸­æå–æ ¸å¿ƒæ¦‚å¿µã€‚"
                        elif round_idx == 2:
                            # ç¬¬äºŒè½®ï¼šä»ä¸åŒè§’åº¦è¡¥å……æœç´¢ï¼ˆé¿å…é‡å¤ï¼‰
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚\n"
                            if section_search_history:
                                strategy_prompt += f"å·²æœç´¢è¿‡ï¼š{section_search_history}ï¼ˆè¿™äº›è§’åº¦å·²è¦†ç›–ï¼‰ã€‚\n"
                            strategy_prompt += f"è¯·ä»**å®Œå…¨ä¸åŒ**çš„è§’åº¦ï¼ˆå¦‚ï¼šé£é™©ç‚¹ã€å®¡æ ¸æ–¹æ³•ã€å¸¸è§é—®é¢˜ã€ç›‘ç®¡è¦æ±‚ç­‰ï¼‰ç”Ÿæˆä¸€ä¸ªæ–°çš„ç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ã€‚å¿…é¡»ä¸å·²æœç´¢å…³é”®è¯ä¸åŒï¼"
                        else:
                            # ç¬¬ä¸‰è½®ï¼šæ·±åº¦å…³è”æœç´¢
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚\n"
                            if section_search_history:
                                strategy_prompt += f"å·²æœç´¢è¿‡ï¼š{section_search_history}ã€‚\n"
                            strategy_prompt += f"è¯·ä»**æ·±å±‚å…³è”**è§’åº¦ï¼ˆå¦‚ï¼šæ³•å¾‹ä¾æ®ã€å¤„ç½šæ¡ˆä¾‹ã€æ“ä½œè§„ç¨‹ç­‰ï¼‰ç”Ÿæˆä¸€ä¸ªæ–°çš„ç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ã€‚å¿…é¡»é¿å…é‡å¤ï¼"

                        try:
                            q_res = await self.llm.ainvoke([HumanMessage(content=strategy_prompt)])
                            query = q_res.content.strip().split('\n')[0].replace('"', '')
                            # ç¡®ä¿ä¸é‡å¤
                            if query in section_search_history:
                                query = f"{section_title.split(' ')[0]}æ£€æŸ¥" if round_idx == 2 else f"{section_title.split(' ')[0]}é£é™©"
                        except Exception:
                            query = self._get_ui_text("default_query", language)

                        section_search_history.append(query)
                        search_keyword = self._get_ui_text("search_keyword", language)
                        yield self._sse("thought", f"[Round {round_idx}] {search_keyword}ï¼š'{query}'")
                        yield self._sse("rag_search", {"query": query})
                        
                        snippet = "ï¼ˆæ— æœ¬åœ°ä¾æ®ï¼‰"
                        score = 0.0
                        filename = "System"
                        
                        if self.kb:
                            try:
                                # å®‰å…¨è°ƒç”¨ï¼Œé˜²æ­¢æ–¹æ³•ä¸å­˜åœ¨
                                search_func = getattr(self.kb, "search_with_score", None)
                                if search_func:
                                    results = await asyncio.wait_for(search_func(query, k=3), timeout=10.0)
                                    if results:
                                        doc, similarity = results[0]
                                        snippet = doc.page_content
                                        filename = Path(doc.metadata.get("source", "unknown")).name
                                        score = similarity
                            except asyncio.TimeoutError:
                                pass # è¶…æ—¶å¿½ç•¥
                            except Exception as e:
                                print(f"æ£€ç´¢å¼‚å¸¸: {e}")

                        yield self._sse("rag_result", {"filename": filename, "score": float(score), "snippet": snippet[:100] + "..."})
                        section_notes.append(f"å…³é”®è¯[{query}] -> {snippet}")
                        state["notebook"].append(f"å…³é”®è¯[{query}] -> {snippet}")
                        
                        yield self._sse("take_note", {"content": f"{query}: {snippet[:20]}..."})
                        await asyncio.sleep(0.1)

                # æ’°å†™æ­£æ–‡
                language_instruction = self._get_language_instruction(language)
                write_prompt = f"""
ä½ æ˜¯ä¸€å{role_desc}ã€‚è¯·æ’°å†™ã€Š{section_title}ã€‹ã€‚
ã€å‰æ–‡ã€‘...{state["full_report_text"][-1000:] if state["full_report_text"] else "æ— "}
ã€è¯æ®ã€‘{json.dumps(section_notes, ensure_ascii=False)}
ã€è¯­è¨€è¦æ±‚ã€‘{language_instruction}
ã€æŒ‡ä»¤ã€‘ç›´æ¥è¾“å‡ºMarkdownæ­£æ–‡ï¼Œä¸è¦é‡å¤æ ‡é¢˜ã€‚
"""
                async for chunk in self.llm.astream([HumanMessage(content=write_prompt)]):
                    if chunk.content:
                        yield self._sse("report_chunk", chunk.content)
                        state["full_report_text"] += chunk.content
                
                state["full_report_text"] += "\n\n"
                yield self._sse("step_done", {"index": i})

            yield self._sse("done", {})

        except Exception as e:
            # æ•æ‰ä»»ä½•é”™è¯¯å¹¶å‘é€ç»™å‰ç«¯
            yield self._sse("error", str(e))

    async def _generate_toc(self, topic: str, mode: str, sop: str, language: str = "zh") -> List[str]:
        """åŒæ¨¡ç›®å½•ç”Ÿæˆå™¨"""
        if mode == "CUSTOMS":
            advice = "å»ºè®®åŒ…å«ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸æ˜¯ä¸€å®šè¦åŒ…å«è¿™äº›ï¼Œä½ éœ€è¦æ ¹æ®å…·ä½“å•æ®æ¥ç¡®å®šï¼‰ï¼š1.ç”³æŠ¥è¦ç´ å¤æ ¸ 2.ä»·æ ¼é€»è¾‘å®¡æŸ¥ 3.è´¸æ˜“ç®¡åˆ¶é£é™© 4.ç»¼åˆç»“è®º"
        else:
            advice = "å»ºè®®åŒ…å«ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸æ˜¯ä¸€å®šè¦åŒ…å«è¿™äº›ï¼Œä½ éœ€è¦æ ¹æ®å…·ä½“å•æ®æ¥ç¡®å®šï¼‰ï¼š1.èƒŒæ™¯æ¦‚è¿° 2.æ ¸å¿ƒäº‹å®æ¢³ç† 3.æ·±åº¦å…³è”åˆ†æ 4.ç»“è®ºä¸å±•æœ›"

        language_instruction = self._get_language_instruction(language)
        prompt = f"""
ä½ æ˜¯ä¸€åé«˜çº§åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥è®¾è®¡ç›®å½•ã€‚
è¾“å…¥ï¼š{topic[:200]}
å»ºè®®ç»“æ„ï¼š{advice}
ã€è¯­è¨€è¦æ±‚ã€‘{language_instruction}
ã€ä¸¥æ ¼è¦æ±‚ã€‘
1. åªè¿”å›ä¸€ä¸ªçº¯ JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œå¦‚ ["1. æ ‡é¢˜A", "2. æ ‡é¢˜B"]
2. ç›®å½•æ ‡é¢˜ä½¿ç”¨å¯¹åº”çš„è¯­è¨€ï¼ˆä¸­æ–‡/è¶Šå—è¯­ï¼‰
3. ä¸è¦ Markdownï¼Œä¸è¦è§£é‡Šã€‚
"""
        try:
            res = await self.llm.ainvoke([HumanMessage(content=prompt)])
            text = re.sub(r'```json\s*|\s*```', '', res.content).strip()
            parsed = json.loads(text)
            clean_toc = []
            if isinstance(parsed, list):
                for idx, item in enumerate(parsed):
                    title = str(item) if not isinstance(item, dict) else str(list(item.values())[0])
                    clean_title = re.sub(r'^(\d+\.|Chapter\s*\d+|ç¬¬.+ç« )\s*', '', title).strip()
                    clean_toc.append(f"{idx + 1}. {clean_title}")
            return clean_toc if clean_toc else self._fallback_toc(mode, language)
        except Exception:
            return self._fallback_toc(mode, language)

    def _fallback_toc(self, mode, language: str = "zh"):
        if mode == "CUSTOMS":
            if language == "vi":
                return ["1. Kiá»ƒm tra cÃ¡c yáº¿u tá»‘ khai bÃ¡o", "2. PhÃ¢n tÃ­ch logic giÃ¡", "3. SÃ ng lá»c giáº¥y phÃ©p giÃ¡m sÃ¡t", "4. Káº¿t luáº­n vÃ  khuyáº¿n nghá»‹"]
            return ["1. ç”³æŠ¥è¦ç´ å¤æ ¸", "2. ä»·æ ¼é€»è¾‘åˆ†æ", "3. ç›‘ç®¡è¯ä»¶ç­›æŸ¥", "4. ç»“è®ºä¸å»ºè®®"]
        if language == "vi":
            return ["1. Tá»•ng quan vá» bá»‘i cáº£nh", "2. PhÃ¢n tÃ­ch cÃ¡c sá»± kiá»‡n cá»‘t lÃµi", "3. PhÃ¢n tÃ­ch liÃªn káº¿t sÃ¢u", "4. Káº¿t luáº­n vÃ  triá»ƒn vá»ng"]
        return ["1. èƒŒæ™¯æ¦‚è¿°", "2. æ ¸å¿ƒäº‹å®æ¢³ç†", "3. æ·±åº¦å…³è”åˆ†æ", "4. ç»“è®ºä¸å±•æœ›"]

    def _sse(self, type_str, payload):
        return f"data: {json.dumps({'type': type_str, 'payload': payload}, ensure_ascii=False)}\n\n"

    def _get_language_instruction(self, language: str) -> str:
        """ç”Ÿæˆè¯­è¨€è¾“å‡ºæŒ‡ä»¤"""
        # è¯­è¨€ä»£ç æ˜ å°„åˆ°å®é™…è¯­è¨€åç§°
        language_names = {
            "zh": "ç®€ä½“ä¸­æ–‡ (Chinese)",
            "vi": "Tiáº¿ng Viá»‡t (è¶Šå—è¯­)"
        }
        language_name = language_names.get(language, language_names["zh"])

        return f"""ã€é‡è¦è¯­è¨€è®¾ç½®ã€‘å½“å‰ç”¨æˆ·è®¾ç½®çš„è¯­è¨€æ˜¯ {language_name}ï¼Œè¯­è¨€ä»£ç ä¸º {language}ã€‚
ã€ä¸¥æ ¼è¦æ±‚ã€‘ä½ å¿…é¡»ä½¿ç”¨ {language_name} æ’°å†™æŠ¥å‘Šå†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€ç»“è®ºç­‰æ‰€æœ‰éƒ¨åˆ†ã€‚
æŠ¥å‘Šçš„æ‰€æœ‰è¾“å‡ºå¿…é¡»æ˜¯ {language_name}ï¼Œè¿™æ˜¯ç”¨æˆ·ç•Œé¢è¯­è¨€è®¾ç½®ï¼ŒæŠ¥å‘Šå°†ç›´æ¥æ˜¾ç¤ºç»™å‰ç«¯ç”¨æˆ·ã€‚"""

    def _get_ui_text(self, key: str, language: str = "zh") -> str:
        """è·å–UIæ˜¾ç¤ºæ–‡å­—"""
        ui_texts = {
            "zh": {
                "building_outline": "æ­£åœ¨åŸºäº",
                "reviewing_full_text": "æ­£åœ¨å›é¡¾å…¨æ–‡ï¼Œè¿›è¡Œé€»è¾‘æ”¶æŸä¸æœ€ç»ˆç ”åˆ¤",
                "search_keyword": "æ£€ç´¢å…³é”®è¯",
                "searching": "æ­£åœ¨æœç´¢",
                "writing": "æ­£åœ¨æ’°å†™",
                "default_query": "é€šç”¨é£é™©",
                "engine_start": "ç ”åˆ¤å¼•æ“å·²å¯åŠ¨ï¼Œæ­£åœ¨åˆ†æä»»åŠ¡æ„å›¾...",
                "role_customs": "æµ·å…³é«˜çº§æŸ¥éªŒä¸“å®¶",
                "task_customs": "è¿›è¡Œè¿›å‡ºå£åˆè§„æ€§å®¡æŸ¥",
                "audit_mode": "æ£€æµ‹åˆ°æŠ¥å…³å•æ®ï¼Œå·²åˆ‡æ¢è‡³ã€åˆè§„å®¡è®¡æ¨¡å¼ã€‘...",
                "role_research": "æ·±åº¦æ¡£æ¡ˆåˆ†æå¸ˆ",
                "task_research": "è¿›è¡Œæœ¬åœ°çŸ¥è¯†åº“æ·±åº¦æŒ–æ˜ä¸ç ”åˆ¤",
                "research_mode": "æ£€æµ‹åˆ°é€šç”¨é—®é¢˜ï¼Œå·²åˆ‡æ¢è‡³ã€æ·±åº¦ç ”åˆ¤æ¨¡å¼ã€‘..."
            },
            "vi": {
                "building_outline": "Äang xÃ¢y dá»±ng",
                "reviewing_full_text": "Äang xem láº¡i toÃ n vÄƒn, thá»±c hiá»‡n káº¿t luáº­n logic cuá»‘i cÃ¹ng",
                "search_keyword": "Tá»« khÃ³a tÃ¬m kiáº¿m",
                "searching": "Äang tÃ¬m kiáº¿m",
                "writing": "Äang viáº¿t",
                "default_query": "Rá»§i ro chung",
                "engine_start": "Äá»™ng cÆ¡ phÃ¢n tÃ­ch Ä‘Ã£ khá»Ÿi Ä‘á»™ng, Ä‘ang phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh nhiá»‡m vá»¥...",
                "role_customs": "ChuyÃªn gia kiá»ƒm tra háº£i quan cáº¥p cao",
                "task_customs": "Thá»±c hiá»‡n xem xÃ©t tuÃ¢n thá»§ xuáº¥t nháº­p kháº©u",
                "audit_mode": "PhÃ¡t hiá»‡n tá» khai háº£i quan, Ä‘Ã£ chuyá»ƒn sangã€Cháº¿ Ä‘á»™ kiá»ƒm toÃ¡n tuÃ¢n thá»§ã€‘...",
                "role_research": "ChuyÃªn gia phÃ¢n tÃ­ch há»“ sÆ¡ sÃ¢u",
                "task_research": "Thá»±c hiá»‡n khai thÃ¡c vÃ  nghiÃªn cá»©u sÃ¢u cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»‹a phÆ°Æ¡ng",
                "research_mode": "PhÃ¡t hiá»‡n váº¥n Ä‘á» chung, Ä‘Ã£ chuyá»ƒn sangã€Cháº¿ Ä‘á»™ nghiÃªn cá»©u sÃ¢uã€‘..."
            }
        }
        return ui_texts.get(language, ui_texts["zh"]).get(key, ui_texts["zh"][key])