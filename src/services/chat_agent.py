import os
import httpx
import asyncio
import json

# ============================================================
# â¬‡ï¸â¬‡ï¸â¬‡ï¸ ã€ç¯å¢ƒé…ç½®ã€‘ â¬‡ï¸â¬‡ï¸â¬‡ï¸
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HUB_DISABLE_SSL_VERIFY'] = '1'
os.environ['CURL_CA_BUNDLE'] = ''
# ============================================================

from langgraph.prebuilt import create_react_agent 
from langchain_openai import ChatOpenAI
from langchain_core.tools import Tool
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from src.config.loader import settings

# çŸ¥è¯†åº“å®¹é”™
try:
    from src.services.knowledge_base import KnowledgeBase
    print("âœ… KnowledgeBase æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ [System] KnowledgeBase å¯¼å…¥å¤±è´¥: {e}")
    KnowledgeBase = None

MEMORY = InMemorySaver()

class CustomsChatAgent:
    def __init__(self):
        print("ğŸ”— [System] åˆå§‹åŒ– Agent (DeepSeek å…¼å®¹ç‰ˆ)...")
        
        # --- 1. ç½‘ç»œå®¢æˆ·ç«¯é…ç½® ---
        proxy_url = settings.HTTP_PROXY if hasattr(settings, 'HTTP_PROXY') and settings.HTTP_PROXY else None
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        if proxy_url:
            async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
            async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)
        else:
            async_client = httpx.AsyncClient(verify=False, timeout=120.0)

        # --- 2. åˆå§‹åŒ– LLM (å…³é”®é…ç½®) ---
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL,
            temperature=0.3,
            http_async_client=async_client,
            streaming=True,
            # ã€æ ¸å¿ƒä¿®å¤ã€‘DeepSeek ç»‘å®šå·¥å…·åå¿…é¡»ç¦ç”¨å¹¶è¡Œè°ƒç”¨æ‰èƒ½æµå¼è¾“å‡º
            model_kwargs={
                "stream": True,
                "parallel_tool_calls": False, 
                "stream_options": {"include_usage": False}
            }
        )

        # --- 3. å·¥å…·é…ç½® ---
        tools = []
        self.retriever = None
        if KnowledgeBase:
            try:
                self.kb = KnowledgeBase()
                self.retriever = self.kb.get_retriever()
                
                def retrieve_docs(query: str) -> str:
                    if not self.retriever: return "çŸ¥è¯†åº“æœªåˆå§‹åŒ–ã€‚"
                    try:
                        print(f"ğŸ” [RAG] æ­£åœ¨æ£€ç´¢: {query}")
                        docs = self.retriever.invoke(query)
                        return "\n\n".join([doc.page_content for doc in docs]) if docs else "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"
                    except Exception as e:
                        return f"æ£€ç´¢å¤±è´¥: {str(e)}"

                retriever_tool = Tool(
                    name="search_customs_regulations",
                    func=retrieve_docs,
                    description="æŸ¥è¯¢æµ·å…³æ³•è§„ã€æ”¿ç­–ã€HSç¼–ç æˆ–æŠ¥å…³æµç¨‹ã€‚æ¶‰åŠæ­¤ç±»é—®é¢˜å¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ã€‚"
                )
                tools.append(retriever_tool)
                print("âœ… çŸ¥è¯†åº“å·¥å…·åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")
        
        # --- 4. ä¿å­˜ç³»ç»Ÿæç¤ºè¯ (ç¨ååœ¨å¯¹è¯æ—¶æ³¨å…¥) ---
        self.system_prompt_text = """
        ä½ æ˜¯ä¸€åä¸“ä¸šã€ä¸¥è°¨çš„æµ·å…³æ³•è§„å’¨è¯¢ä¸“å®¶ã€‚
        è§„åˆ™:
        1. å¿…é¡»ä¼˜å…ˆä½¿ç”¨ `search_customs_regulations` å·¥å…·æŸ¥è¯¢ä¸“ä¸šé—®é¢˜ã€‚
        2. é—²èŠæˆ–æ™®é€šé—®å€™å¯ä»¥ç›´æ¥å›ç­”ï¼Œæ— éœ€æŸ¥åº“ã€‚
        3. å›ç­”å¿…é¡»ç®€æ´ã€ä¸“ä¸šã€‚
        """

        # --- 5. åˆ›å»º Agent (æœ€ç®€å‚æ•°ï¼Œé¿å¼€ç‰ˆæœ¬å†²çª) ---
        # æˆ‘ä»¬ä¸åœ¨è¿™é‡Œä¼  system_prompt/state_modifierï¼Œé¿å…æŠ¥é”™
        self.agent = create_react_agent(
            model=self.llm,
            tools=tools,
            checkpointer=MEMORY,
        )
        print("âœ… æ™ºèƒ½ä½“æ„å»ºå®Œæˆ")

        # é¢„çƒ­
        if self.retriever:
            try:
                self.retriever.invoke("warm-up") 
            except: pass

    async def chat_stream(self, user_input: str, session_id: str = "default_session"):
        """
        æ‰§è¡Œ Agent æµå¼è°ƒç”¨
        """
        try:
            print(f"\nğŸ‘‰ [Request] {user_input}")
            yield f"data: {json.dumps({'type': 'thinking', 'content': 'æ™ºèƒ½ä½“æ­£åœ¨æ€è€ƒ...'}, ensure_ascii=False)}\n\n"
            
            config = {"configurable": {"thread_id": session_id}}
            has_sent_content = False

            # ã€æ„å»ºæ¶ˆæ¯åˆ—è¡¨ã€‘æ‰‹åŠ¨å°† SystemPrompt æ’åœ¨æœ€å‰é¢
            input_messages = [
                SystemMessage(content=self.system_prompt_text),
                HumanMessage(content=user_input)
            ]

            # ä½¿ç”¨ astream_events v2 ç›‘å¬åº•å±‚ Token
            async for event in self.agent.astream_events(
                {"messages": input_messages}, # ä¼ å…¥åŒ…å«ç³»ç»Ÿæç¤ºçš„æ¶ˆæ¯åˆ—è¡¨
                config=config,
                version="v2" 
            ):
                event_type = event["event"]
                
                # 1. ç›‘å¬ LLM çš„æµå¼è¾“å‡º
                if event_type == "on_chat_model_stream":
                    chunk = event["data"]["chunk"]
                    
                    # A. æ•è·æ­£æ–‡å†…å®¹
                    if chunk.content:
                        has_sent_content = True
                        # ä½¿ç”¨ json.dumps è‡ªåŠ¨å¤„ç†è½¬ä¹‰ï¼Œä¸è¦æ‰‹åŠ¨ replace
                        payload = {"type": "answer", "content": chunk.content}
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                    
                    # B. æ•è· DeepSeek çš„æ€è€ƒè¿‡ç¨‹
                    reasoning = chunk.additional_kwargs.get('reasoning_content', '')
                    if reasoning:
                        payload = {"type": "thinking", "content": reasoning}
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"

                    await asyncio.sleep(0.01)
                    
                # 2. ç›‘å¬å·¥å…·å¼€å§‹è°ƒç”¨
                elif event_type == "on_tool_start":
                    tool_name = event["name"]
                    print(f"ğŸ› ï¸ [å·¥å…·] {tool_name} å¯åŠ¨")
                    yield f"data: {json.dumps({'type': 'thinking', 'content': f'æ­£åœ¨è°ƒç”¨å·¥å…·[{tool_name}]...'}, ensure_ascii=False)}\n\n"

                # 3. ç›‘å¬å·¥å…·ç»“æŸ
                elif event_type == "on_tool_end":
                    print(f"âœ… [å·¥å…·] å®Œæˆ")
                    yield f"data: {json.dumps({'type': 'thinking', 'content': 'æŸ¥è¯¢å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...'}, ensure_ascii=False)}\n\n"

            # =======================================================
            # ä¿åº•é€»è¾‘
            # =======================================================
            if not has_sent_content:
                print("âš ï¸ [è­¦å‘Š] æµå¼æœªè§¦å‘ï¼Œå°è¯•è·å–æœ€ç»ˆçŠ¶æ€...")
                final_state = await self.agent.aget_state(config)
                if final_state.values and "messages" in final_state.values:
                    last_msg = final_state.values["messages"][-1]
                    if isinstance(last_msg, AIMessage) and last_msg.content:
                        payload = {"type": "answer", "content": last_msg.content}
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"

            print("âœ… [è¯·æ±‚ç»“æŸ] å®Œæˆ\n")

        except Exception as e:
            print(f"âŒ [Error] {e}")
            import traceback
            traceback.print_exc()
            payload = {"type": "error", "content": f"ç³»ç»Ÿé”™è¯¯: {str(e)}"}
            yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"