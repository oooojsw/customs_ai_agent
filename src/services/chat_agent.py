import os
import httpx
import asyncio
import json
import sys
import io
from typing import List, Optional, Any

# ============================================================
# â¬‡ï¸â¬‡ï¸â¬‡ï¸ ã€ç¯å¢ƒé…ç½® - éµä» 1222.txt ä¿®å¤ç»éªŒã€‘ â¬‡ï¸â¬‡ï¸â¬‡ï¸
# ============================================================
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HUB_DISABLE_SSL_VERIFY'] = '1'
os.environ['CURL_CA_BUNDLE'] = ''

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜ï¼Œç¡®ä¿æ§åˆ¶å°è¾“å‡ºä¸­æ–‡ä¸ä¹±ç 
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

from langgraph.prebuilt import create_react_agent 
from langchain_openai import ChatOpenAI
from langchain_core.tools import Tool
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# å¯¼å…¥é¡¹ç›®é…ç½®å’Œä¸šåŠ¡ç»„ä»¶
from src.config.loader import settings
from src.core.orchestrator import RiskAnalysisOrchestrator

# çŸ¥è¯†åº“æ¨¡å—å®¹é”™å¤„ç†
try:
    from src.services.knowledge_base import KnowledgeBase
    print("[ChatAgent] æˆåŠŸåŠ è½½çŸ¥è¯†åº“æ¨¡å— (RAG System Ready)")
except ImportError as e:
    print(f"[Warning] çŸ¥è¯†åº“æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    KnowledgeBase = None

# åˆå§‹åŒ–å†…å­˜æ£€æŸ¥ç‚¹ï¼Œç”¨äºç»´æŠ¤å¤šè½®å¯¹è¯çŠ¶æ€
MEMORY = InMemorySaver()

class CustomsChatAgent:
    def __init__(self, kb=None, llm_config: dict = None):
        """
        åˆå§‹åŒ–æµ·å…³æ™ºèƒ½å¯¹è¯ä»£ç† (v3.1.3 æ·±åº¦é›†æˆç‰ˆ)
        å·²ä¿®å¤ Tool.__init__ ç¼ºå¤± func å‚æ•°å¯¼è‡´çš„ 500 é”™è¯¯ã€‚
        """
        print("[System] æ­£åœ¨åˆå§‹åŒ–å…¨èƒ½æ™ºèƒ½ä½“ (DeepSeek Streaming + Audit Tool)...")

        # --- 1. è·å–å¹¶æ ¼å¼åŒ– LLM é…ç½® ---
        if llm_config:
            self.config = llm_config
            print(f"[ChatAgent] ä½¿ç”¨åŠ¨æ€ LLM é…ç½®: {self.config.get('model')}")
        else:
            self.config = {
                'api_key': settings.DEEPSEEK_API_KEY,
                'base_url': settings.DEEPSEEK_BASE_URL,
                'model': settings.DEEPSEEK_MODEL,
                'temperature': 0.3,
            }
            print("[ChatAgent] ä½¿ç”¨ .env é»˜è®¤é…ç½®")

        # --- 2. ç½‘ç»œå®¢æˆ·ç«¯é…ç½® ---
        proxy_url = settings.HTTP_PROXY if hasattr(settings, 'HTTP_PROXY') and settings.HTTP_PROXY else None
        if proxy_url:
            async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
            self._async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)
        else:
            self._async_client = httpx.AsyncClient(verify=False, timeout=120.0)

        # --- 3. åˆå§‹åŒ–æ ¸å¿ƒ LLM ---
        self.llm = ChatOpenAI(
            model=self.config['model'],
            api_key=self.config['api_key'],
            base_url=self.config['base_url'],
            temperature=self.config.get('temperature', 0.3),
            http_async_client=self._async_client,
            streaming=True,
            model_kwargs={
                "stream": True,
                "parallel_tool_calls": False, # DeepSeek ä¸“ç”¨æµå¼è¡¥ä¸
            }
        )

        # --- 4. æ„å»ºå·¥å…·é›† ---
        self.tools = []

        # å®šä¹‰å¼‚æ­¥å®¡å•å‡½æ•°
        async def audit_declaration_tool(raw_data: str) -> str:
            """
            å½“ç”¨æˆ·æä¾›ä¸€æ®µæŠ¥å…³å•æ•°æ®å¹¶è¦æ±‚å®¡æ ¸é£é™©æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚è¾“å…¥åº”ä¸ºå®Œæ•´çš„æŠ¥å…³å•åŸæ–‡ã€‚
            """
            print(f"ğŸš€ [Tool Call] æ™ºèƒ½å®¡å•å¼•æ“æ­£åœ¨æ‰§è¡Œ...")
            orch = RiskAnalysisOrchestrator(llm_config=self.config)
            findings = []
            
            async for event_str in orch.analyze_stream(raw_data, language="zh"):
                if not event_str.startswith("data: "): continue
                try:
                    data = json.loads(event_str[6:])
                    if data["type"] == "step_result":
                        status_symbol = "âœ…" if data["status"] == "pass" else "âŒ"
                        findings.append(f"{status_symbol} {data['rule_id']}: {data['message']}")
                    elif data["type"] == "complete":
                        findings.append(f"\nã€å®¡è®¡æœ€ç»ˆè¯„ä¼°ã€‘\n{data['summary']}")
                except: continue
            
            return "\n".join(findings) if findings else "å®¡å•å¼•æ“æœªäº§ç”Ÿæœ‰æ•ˆç»“è®ºã€‚"

        # ã€ä¿®å¤ç‚¹ã€‘ä½¿ç”¨ Tool æ—¶æ˜¾å¼æä¾› func (åŒæ­¥å ä½) å’Œ coroutine (å¼‚æ­¥å®ç°)
        self.tools.append(Tool(
            name="audit_declaration",
            func=lambda x: "æ­¤å·¥å…·ä»…æ”¯æŒå¼‚æ­¥ç¯å¢ƒè¿è¡Œ", # å ä½ï¼Œé˜²æ­¢åˆå§‹åŒ–æŠ¥é”™
            coroutine=audit_declaration_tool,      # å®é™…å¼‚æ­¥é€»è¾‘
            description="å…¨è‡ªåŠ¨æŠ¥å…³é£é™©æ‰«æå·¥å…·ã€‚èƒ½æ£€æµ‹è¦ç´ å®Œæ•´æ€§ã€æ•æ„Ÿç‰©é¡¹ã€ä»·æ ¼é€»è¾‘ã€å½’ç±»ä¸€è‡´æ€§åŠå•è¯ä¸€è‡´æ€§ã€‚"
        ))

        # RAG çŸ¥è¯†åº“æ£€ç´¢å·¥å…·
        if KnowledgeBase:
            self.kb = kb if kb else KnowledgeBase()
            self.retriever = self.kb.get_retriever()

            def retrieve_docs(query: str) -> str:
                if not self.retriever: return "çŸ¥è¯†åº“æœªå°±ç»ªã€‚"
                try:
                    print(f"ğŸ” [Tool Call] æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“: {query}")
                    docs = self.retriever.invoke(query)
                    if not docs: return "æœ¬åœ°æ³•è§„åº“ä¸­æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„ä¾æ®ã€‚"
                    return "\n\n".join([doc.page_content for doc in docs])
                except Exception as e:
                    return f"çŸ¥è¯†åº“æ£€ç´¢å¼‚å¸¸: {str(e)}"

            self.tools.append(Tool(
                name="search_customs_regulations",
                func=retrieve_docs, 
                description="æŸ¥è¯¢æµ·å…³ç›¸å…³æ³•è§„ã€æ”¿ç­–æ–‡ä»¶ã€HSç¼–ç è§£é‡Šã€‚é‡åˆ°ä¸“ä¸šåè¯æˆ–æ³•å¾‹ç–‘é—®æ—¶å¿…é¡»ä½¿ç”¨ã€‚"
            ))

        # --- 5. æ„å»ºå›¾æ™ºèƒ½ä½“ ---
        self.system_prompt_text = """
        ä½ æ˜¯ä¸€åæ™ºæ…§å£å²¸AIä¸“å®¶ï¼Œè´Ÿè´£æŠ¥å…³å’¨è¯¢å’Œè‡ªåŠ¨å®¡å•ã€‚
        å·¥ä½œå®ˆåˆ™ï¼š
        1. å®¡è®¡ï¼šç”¨æˆ·ç²˜è´´æŠ¥å…³å•åï¼Œä¸»åŠ¨è°ƒç”¨ `audit_declaration`ã€‚
        2. å’¨è¯¢ï¼šæ³•å¾‹ç–‘é—®è°ƒç”¨ `search_customs_regulations`ã€‚
        3. ååŒï¼šå®¡å•å‘ç°é£é™©åï¼Œå¯æ£€ç´¢æ³•è§„æ¡æ–‡æ¥æ”¯æ’‘ä½ çš„è§£é‡Šã€‚
        4. è¯­è¨€ï¼šä¸¥ç¦è·³å‡ºç”¨æˆ·å½“å‰ä½¿ç”¨çš„è¯­è¨€ï¼ˆä¸­æ–‡æˆ–è¶Šå—è¯­ï¼‰ã€‚
        """

        self.agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
            checkpointer=MEMORY,
        )
        print(f"[ChatAgent] æ™ºèƒ½ä½“å°±ç»ªï¼Œå·¥å…·åˆ—è¡¨: {[t.name for t in self.tools]}")

    async def chat_stream(self, user_input: str, session_id: str = "default_session", language: str = "zh"):
        """
        æ ¸å¿ƒæµå¼åˆ†å‘å™¨
        """
        try:
            print(f"\nğŸ‘‰ [Request] {user_input}")
            
            lang_inst = self._get_language_instruction(language)
            input_messages = [
                SystemMessage(content=f"{self.system_prompt_text}\n\n{lang_inst}"),
                HumanMessage(content=user_input)
            ]

            config = {"configurable": {"thread_id": session_id}}
            has_sent_content = False

            # ä½¿ç”¨ astream_events v2 å®ç°æè‡´æ‰“å­—æœºæ•ˆæœ
            async for event in self.agent.astream_events(
                {"messages": input_messages},
                config=config,
                version="v2" 
            ):
                event_type = event["event"]
                
                if event_type == "on_chat_model_stream":
                    chunk = event["data"].get("chunk")
                    if not chunk: continue
                    
                    # æå–æ­£æ–‡
                    content = getattr(chunk, 'content', '')
                    if content:
                        has_sent_content = True
                        yield f"data: {json.dumps({'type': 'answer', 'content': content}, ensure_ascii=False)}\n\n"
                    
                    # æå–æ€è€ƒæµ
                    add_kwargs = getattr(chunk, 'additional_kwargs', {})
                    reasoning = add_kwargs.get('reasoning_content', '')
                    if reasoning:
                        yield f"data: {json.dumps({'type': 'thinking', 'content': reasoning}, ensure_ascii=False)}\n\n"

                elif event_type == "on_tool_start":
                    t_name = event["name"]
                    yield f"data: {json.dumps({'type': 'thinking', 'content': f'ä¸“å®¶æ­£åœ¨ä½¿ç”¨å·¥å…· [{t_name}] æ·±åº¦åˆ†æä¸­...'}, ensure_ascii=False)}\n\n"

            if not has_sent_content:
                # ä¿åº•
                state = await self.agent.aget_state(config)
                if state.values and "messages" in state.values:
                    last_msg = state.values["messages"][-1]
                    if isinstance(last_msg, AIMessage) and last_msg.content:
                        yield f"data: {json.dumps({'type': 'answer', 'content': last_msg.content}, ensure_ascii=False)}\n\n"

        except Exception as e:
            print(f"ğŸ’¥ [Fatal] {str(e)}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'content': f'ç³»ç»Ÿå¼‚å¸¸: {str(e)}'}, ensure_ascii=False)}\n\n"

    def _get_language_instruction(self, language: str) -> str:
        names = {"zh": "ç®€ä½“ä¸­æ–‡", "vi": "Tiáº¿ng Viá»‡t"}
        target = names.get(language, "ç®€ä½“ä¸­æ–‡")
        return f"ã€é‡è¦è®¾ç½®ã€‘å½“å‰è¯­è¨€ä¸º {target}ã€‚ä½ å¿…é¡»ä»¥æ­¤è¯­è¨€è¿›è¡Œå›å¤ã€‚"

if __name__ == "__main__":
    print("Chat Agent Service defined.")