import json
import asyncio
import httpx
import random
import re
from typing import List, AsyncGenerator, Set, Tuple
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from pathlib import Path

# å¯¼å…¥é…ç½®
from src.config.loader import settings

# çŸ¥è¯†åº“å®¹é”™å¯¼å…¥
try:
    from src.services.knowledge_base import KnowledgeBase
    KB_AVAILABLE = True
except ImportError:
    KnowledgeBase = None
    KB_AVAILABLE = False
    print("âš ï¸ [System] KnowledgeBase æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä»¥æ— çŸ¥è¯†åº“æ¨¡å¼è¿è¡Œ")

# ==================== AI å†³ç­–ç³»ç»Ÿæ•°æ®ç»“æ„ ====================

@dataclass
class SearchRecord:
    """å•æ¬¡æ£€ç´¢è®°å½•"""
    round: int
    query: str
    snippet: str
    score: float


@dataclass
class ResearchContext:
    """æ£€ç´¢ä¸Šä¸‹æ–‡"""
    # ç« èŠ‚ä¿¡æ¯
    chapter_index: int           # å½“å‰ç« èŠ‚åºå· (1-based)
    chapter_title: str           # ç« èŠ‚æ ‡é¢˜
    total_chapters: int          # æ€»ç« èŠ‚æ•°

    # è½®æ¬¡ä¿¡æ¯
    current_round: int           # å½“å‰è½®æ¬¡ (1-based)
    min_rounds: int              # æœ€å°è½®æ•°
    max_rounds: int              # æœ€å¤§è½®æ•°
    mode: str                    # "CUSTOMS" æˆ– "RESEARCH"

    # æ£€ç´¢å†å² (æ¯è½®çš„è®°å½•)
    search_history: List[SearchRecord]

    # å½“å‰æ£€ç´¢ç»“æœ
    current_query: str
    current_snippet: str
    current_score: float


@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    # åŸºç¡€è¯„åˆ† (0-1)
    score_component: float      # ç›¸ä¼¼åº¦ Ã— 40%
    richness_component: float   # ä¸°å¯Œåº¦ Ã— 30%
    dedup_component: float      # å»é‡ Ã— 20%
    evidence_component: float   # ç´¯ç§¯è¯æ® Ã— 10%

    # ç»¼åˆè¯„åˆ†
    total_quality: float        # æ€»åˆ† (0-1)

    # è´¨é‡ç­‰çº§
    quality_level: str          # "ä¼˜ç§€"/"ä¸­ç­‰"/"è¾ƒå·®"
    quality_stars: str          # "â­â­â­"/"â­â­"/"â­"

    # è¶‹åŠ¿åˆ†æ
    trend_indicator: str        # "â†‘0.05"/"â†“0.08"/"â†’æŒå¹³"

    # å†…å®¹ç‰¹å¾
    has_numbers: bool
    has_punctuation: bool
    has_citation: bool

    # è¯æ®åˆ†æ
    coverage_areas: Set[str]    # å·²è¦†ç›–çš„é¢†åŸŸ
    sufficiency_percent: float  # å……åˆ†æ€§ç™¾åˆ†æ¯”
    duplication_percent: float  # é‡å¤åº¦ç™¾åˆ†æ¯”


class ComplianceReporter:
    def __init__(self):
        print("ğŸ“‘ [System] åˆå§‹åŒ– ComplianceReporter...")
        
        # 1. ç½‘ç»œå±‚é…ç½®
        proxy_url = settings.HTTP_PROXY
        # å¼ºåˆ¶å…³é—­ SSL éªŒè¯
        if proxy_url:
            async_transport = httpx.AsyncHTTPTransport(proxy=proxy_url, verify=False)
            self.async_client = httpx.AsyncClient(transport=async_transport, timeout=120.0)
        else:
            self.async_client = httpx.AsyncClient(verify=False, timeout=120.0)

        # 2. LLM åˆå§‹åŒ–
        self.llm = ChatOpenAI(
            model=settings.DEEPSEEK_MODEL,
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_BASE_URL,
            temperature=0.3,
            http_async_client=self.async_client,
            streaming=True,
            model_kwargs={"stream": True}
        )

        # 3. çŸ¥è¯†åº“æ£€ç´¢å™¨
        self.kb = None
        if KB_AVAILABLE:
            try:
                self.kb = KnowledgeBase()
            except Exception as e:
                print(f"   âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ (è·³è¿‡): {e}")

        # 4. åŠ è½½åŒæ¨¡ SOP
        self.sop_customs = self._load_specific_sop("sop_process.txt", "æ ‡å‡†æµ·å…³åˆè§„å®¡æŸ¥SOP")
        self.sop_research = self._load_specific_sop("sop_deep_research.txt", "é€šç”¨æ·±åº¦ç ”åˆ¤SOP")

    def _load_research_config(self) -> dict:
        """åŠ è½½æ™ºèƒ½æ£€ç´¢é…ç½®"""
        try:
            base_dir = Path(__file__).resolve().parent.parent.parent
            config_path = base_dir / "config" / "research_config.json"

            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            else:
                # é»˜è®¤é…ç½®
                return {
                    "version": "1.0",
                    "rules": {
                        "CUSTOMS": {"min_rounds": 1, "max_rounds": 4, "early_stop_threshold": 0.75, "force_continue_threshold": 0.4},
                        "RESEARCH": {"min_rounds": 2, "max_rounds": 5, "early_stop_threshold": 0.7, "force_continue_threshold": 0.45}
                    },
                    "quality_metrics": {
                        "score_weight": 0.4, "content_weight": 0.3, "dedup_weight": 0.2, "evidence_weight": 0.1,
                        "min_content_length": 50, "dedup_threshold": 0.85
                    }
                }
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ£€ç´¢é…ç½®å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            return {"rules": {"CUSTOMS": {"min_rounds": 1, "max_rounds": 3, "early_stop_threshold": 0.7},
                             "RESEARCH": {"min_rounds": 2, "max_rounds": 4, "early_stop_threshold": 0.7}},
                    "quality_metrics": {"score_weight": 0.4, "content_weight": 0.3, "dedup_weight": 0.2, "evidence_weight": 0.1}}

    def _load_specific_sop(self, filename: str, default_text: str) -> str:
        try:
            base_dir = Path(__file__).resolve().parent.parent.parent
            sop_path = base_dir / "config" / filename
            if sop_path.exists():
                with open(sop_path, "r", encoding="utf-8") as f:
                    return f.read()
            return default_text
        except:
            return default_text

    def _validate_and_fix_filename(self, raw_filename: str) -> str:
        """
        éªŒè¯ä» FAISS metadata æå–çš„æ–‡ä»¶åï¼Œç¡®ä¿å…¶ç¡®å®å­˜åœ¨äº knowledge ç›®å½•ã€‚
        å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ä¿®å¤æ–‡ä»¶åã€‚
        """
        from pathlib import Path

        # è·å– knowledge ç›®å½•
        base_dir = Path(__file__).resolve().parent.parent.parent
        knowledge_dir = base_dir / "data" / "knowledge"

        # å¦‚æœæ–‡ä»¶åä¸ºç©ºæˆ–å¼‚å¸¸ï¼Œè¿”å›é»˜è®¤å€¼
        if not raw_filename or raw_filename in ["unknown", "System"]:
            return raw_filename

        # ç­–ç•¥1: æ£€æŸ¥åŸå§‹æ–‡ä»¶åæ˜¯å¦å­˜åœ¨
        possible_names = [
            raw_filename,
            raw_filename + ".txt",
            raw_filename.replace('.txt', ''),
        ]

        for name in possible_names:
            file_path = knowledge_dir / name
            if file_path.exists() and file_path.is_file():
                return name  # è¿”å›æ‰¾åˆ°çš„æ–‡ä»¶å

        # ç­–ç•¥2: å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        try:
            # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
            all_files = list(knowledge_dir.glob('*'))

            # ä¼˜å…ˆçº§1: å®Œå…¨åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œæ‰©å±•åï¼‰
            for file_path in all_files:
                if file_path.is_file():
                    file_name = file_path.name
                    # ç§»é™¤æ‰©å±•ååæ¯”è¾ƒ
                    raw_no_ext = Path(raw_filename).stem
                    file_no_ext = file_path.stem

                    if raw_no_ext.lower() == file_no_ext.lower():
                        return file_name

            # ä¼˜å…ˆçº§2: åŒ…å«åŒ¹é…
            raw_lower = raw_filename.lower()
            for file_path in all_files:
                if file_path.is_file():
                    file_name = file_path.name
                    file_lower = file_name.lower()

                    # æ£€æŸ¥æ˜¯å¦äº’ç›¸åŒ…å«
                    if raw_lower in file_lower or file_lower in raw_lower:
                        return file_name

        except Exception as e:
            print(f"âš ï¸ æ–‡ä»¶åéªŒè¯æ—¶å‡ºé”™: {e}")

        # å¦‚æœæ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡ä»¶åï¼ˆè®©å‰ç«¯ API å»å¤„ç†ï¼‰
        return raw_filename

    def _detect_mode(self, text: str) -> str:
        keywords = ["æŠ¥å…³å•", "HSç¼–ç ", "ç”³æŠ¥è¦ç´ ", "å¢ƒå†…æ”¶è´§äºº", "æˆäº¤æ–¹å¼", "æè¿å•å·", "æ¯›é‡", "å‡€é‡"]
        hit_count = sum(1 for k in keywords if k in text)
        return "CUSTOMS" if hit_count >= 2 else "RESEARCH"

    def _compute_content_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç”¨äºå»é‡ï¼‰"""
        # ä½¿ç”¨å­—ç¬¦çº§åˆ«çš„ Jaccard ç›¸ä¼¼åº¦
        def get_chinese_chars(text):
            return set(c for c in text if '\u4e00' <= c <= '\u9fff')

        chars1 = get_chinese_chars(text1)
        chars2 = get_chinese_chars(text2)

        if not chars1 or not chars2:
            return 0.0

        intersection = chars1 & chars2
        union = chars1 | chars2
        return len(intersection) / len(union) if union else 0.0

    def _evaluate_content_richness(self, snippet: str) -> float:
        """è¯„ä¼°å†…å®¹ä¸°å¯Œåº¦ (0-1)"""
        if not snippet or snippet == "ï¼ˆæ— æœ¬åœ°ä¾æ®ï¼‰":
            return 0.0

        score = 0.0
        length = len(snippet)

        # é•¿åº¦è¯„åˆ†
        if length >= 200: score += 0.4
        elif length >= 100: score += 0.3
        elif length >= 50: score += 0.2
        else: score += 0.1

        # ä¿¡æ¯å¯†åº¦
        if re.search(r'\d+', snippet): score += 0.2  # åŒ…å«æ•°å­—
        if re.search(r'[ï¼š:ã€,ï¼Œ]', snippet): score += 0.2  # åŒ…å«ç»“æ„åŒ–æ ‡ç‚¹
        if re.search(r'(\d+\.|[-â€¢])', snippet): score += 0.2  # åŒ…åˆ—ä¸¾æ ‡è®°

        return min(score, 1.0)

    def _evaluate_cumulative_evidence(self, section_notes: List[str]) -> float:
        """è¯„ä¼°ç´¯ç§¯è¯æ®çš„å……åˆ†åº¦ (0-1)"""
        if not section_notes:
            return 0.0

        combined_text = " ".join(section_notes)
        score = 0.0

        # æ€»ä¿¡æ¯é‡
        total_length = len(combined_text)
        if total_length >= 500: score += 0.4
        elif total_length >= 300: score += 0.3
        elif total_length >= 150: score += 0.2
        else: score += 0.1

        # å…³é”®è¯å¤šæ ·æ€§
        unique_keywords = set(re.findall(r'å…³é”®è¯\[([^\]]+)\]', combined_text))
        if len(unique_keywords) >= 3: score += 0.3
        elif len(unique_keywords) >= 2: score += 0.2
        else: score += 0.1

        # å†…å®¹é‡å¤åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
        if len(section_notes) > 1:
            similarities = []
            for i in range(len(section_notes)):
                for j in range(i+1, len(section_notes)):
                    sim = self._compute_content_similarity(section_notes[i], section_notes[j])
                    similarities.append(sim)
            if similarities:
                avg_sim = sum(similarities) / len(similarities)
                score += (1 - avg_sim) * 0.3

        return min(score, 1.0)

    def _should_continue_research(
        self, current_round: int, snippet: str, score: float,
        section_notes: List[str], mode: str, config: dict
    ) -> tuple[bool, str]:
        """æ™ºèƒ½å†³ç­–æ˜¯å¦ç»§ç»­æ£€ç´¢"""
        mode_config = config["rules"][mode]
        min_rounds = mode_config["min_rounds"]
        max_rounds = mode_config["max_rounds"]
        early_stop_threshold = mode_config["early_stop_threshold"]
        force_continue_threshold = mode_config.get("force_continue_threshold", 0.4)

        # å¼ºåˆ¶è¾¹ç•Œæ¡ä»¶
        if current_round < min_rounds:
            return True, f"æœªè¾¾åˆ°æœ€å°è½®æ•° ({min_rounds})"
        if current_round >= max_rounds:
            return False, f"å·²è¾¾åˆ°æœ€å¤§è½®æ•°é™åˆ¶ ({max_rounds})"

        # è®¡ç®—è´¨é‡è¯„åˆ†
        metrics = config["quality_metrics"]

        score_component = score * metrics["score_weight"]
        richness = self._evaluate_content_richness(snippet)
        richness_component = richness * metrics["content_weight"]

        # å»é‡è¯„ä¼°
        if section_notes:
            max_sim = max(self._compute_content_similarity(snippet, note) for note in section_notes)
            dedup_threshold = metrics.get("dedup_threshold", 0.85)
            dedup_score = 0.0 if max_sim > dedup_threshold else 1.0
        else:
            dedup_score = 1.0

        dedup_component = dedup_score * metrics["dedup_weight"]

        # ç´¯ç§¯è¯æ®åº¦
        evidence_score = self._evaluate_cumulative_evidence(section_notes)
        evidence_component = evidence_score * metrics["evidence_weight"]

        # ç»¼åˆè¯„åˆ†
        total_quality_score = score_component + richness_component + dedup_component + evidence_component

        # å†³ç­–é€»è¾‘
        if total_quality_score >= early_stop_threshold:
            reason = f"è´¨é‡è¯„åˆ† {total_quality_score:.2f} â‰¥ é˜ˆå€¼ {early_stop_threshold}"
            return False, reason

        if total_quality_score < force_continue_threshold and current_round >= min_rounds + 1:
            reason = f"è¿ç»­è´¨é‡è¯„åˆ†è¿‡ä½ ({total_quality_score:.2f}), åœæ­¢ä»¥èŠ‚çœèµ„æº"
            return False, reason

        continue_reason = f"è´¨é‡è¯„åˆ† {total_quality_score:.2f} < é˜ˆå€¼ {early_stop_threshold}, ç»§ç»­æ·±åº¦æ£€ç´¢"
        return True, continue_reason

    # ==================== AI å†³ç­–ç³»ç»Ÿè¾…åŠ©å‡½æ•° ====================

    def _get_quality_rating(self, score: float) -> str:
        """æ ¹æ®ç›¸ä¼¼åº¦è¿”å›æ˜Ÿçº§è¯„çº§"""
        if score >= 0.75: return "â­â­â­"
        elif score >= 0.55: return "â­â­"
        else: return "â­"

    def _build_history_table(self, search_history: List[SearchRecord]) -> str:
        """ç”Ÿæˆæ£€ç´¢å†å² Markdown è¡¨æ ¼"""
        if not search_history:
            return "æ— æ£€ç´¢å†å²"

        # è¡¨å¤´
        header = "è½®æ¬¡ | å…³é”®è¯ | ç›¸ä¼¼åº¦ | å†…å®¹æ‘˜è¦ | è¯„çº§\n"
        separator = "---|---|---|---|---\n"

        # è¡¨è¡Œ (æœ€å¤šæ˜¾ç¤ºå‰3è½®)
        rows = []
        for record in search_history[:3]:
            query_short = record.query[:12] + "..." if len(record.query) > 15 else record.query
            snippet_short = record.snippet[:12] + "..." if len(record.snippet) > 15 else record.snippet
            rating = self._get_quality_rating(record.score)

            row = f"{record.round} | {query_short} | {record.score:.2f} | {snippet_short} | {rating}"
            rows.append(row)

        return header + separator + "\n".join(rows)

    def _calculate_trend(self, current_score: float, history: List[SearchRecord]) -> str:
        """è®¡ç®—è´¨é‡å˜åŒ–è¶‹åŠ¿"""
        if not history:
            return ""

        prev_score = history[-1].score
        diff = current_score - prev_score

        if abs(diff) < 0.03:
            return "â†’æŒå¹³"
        elif diff > 0:
            return f"â†‘{diff:.2f}"
        else:
            return f"â†“{abs(diff):.2f}"

    def _calculate_coverage(self, snippets: List[str]) -> Set[str]:
        """è®¡ç®—è¯æ®è¦†ç›–çš„å…³é”®é¢†åŸŸ"""
        coverage_keywords = {
            "å®¡æ ¸æ ‡å‡†": ["å®¡æ ¸", "æ£€æŸ¥", "æ ‡å‡†", "è¦æ±‚", "è§„èŒƒ"],
            "é£é™©åˆ†æ": ["é£é™©", "é—®é¢˜", "éšæ‚£", "æ³¨æ„"],
            "è¿è§„æ¡ˆä¾‹": ["æ¡ˆä¾‹", "æŸ¥å¤„", "è¿è§„", "è¿æ³•"],
            "å¤„ç½šä¾æ®": ["å¤„ç½š", "æ¡ä¾‹", "æ³•å¾‹", "è§„å®š"],
            "è¡Œä¸šåŸºå‡†": ["å¸‚åœºä»·", "åŸºå‡†", "å‚è€ƒ", "è¡Œä¸š"]
        }

        covered = set()
        all_text = " ".join(snippets)

        for area, keywords in coverage_keywords.items():
            if any(kw in all_text for kw in keywords):
                covered.add(area)

        return covered

    def _build_coverage_checklist(self, covered: Set[str]) -> str:
        """ç”Ÿæˆè¦†ç›–åº¦æ£€æŸ¥æ¸…å•"""
        all_areas = ["å®¡æ ¸æ ‡å‡†", "é£é™©åˆ†æ", "è¿è§„æ¡ˆä¾‹", "å¤„ç½šä¾æ®", "è¡Œä¸šåŸºå‡†"]

        items = []
        for area in all_areas:
            if area in covered:
                items.append(f"âœ…{area}")
            else:
                items.append(f"âŒ{area}")

        return " ".join(items)

    def _calculate_sufficiency(self, coverage: Set[str]) -> Tuple[float, str]:
        """è®¡ç®—è¯æ®å……åˆ†æ€§"""
        total_areas = 5  # æ€»å…±5ä¸ªé¢†åŸŸ
        covered_count = len(coverage)

        percent = covered_count / total_areas

        if percent >= 0.7:
            level = "å……åˆ†"
        elif percent >= 0.5:
            level = "ä¸­ç­‰"
        else:
            level = "ä¸è¶³"

        return percent, level

    def _build_feature_checklist(self, snippet: str) -> str:
        """ç”Ÿæˆå†…å®¹ç‰¹å¾æ£€æŸ¥æ¸…å•"""
        checks = []
        if re.search(r'\d+', snippet):
            checks.append("æ•°å­—âœ“")
        if re.search(r'[ï¼š:ã€,ï¼Œ]', snippet):
            checks.append("æ ‡ç‚¹âœ“")
        if re.search(r'[æ¡ä¾‹]{2}|ç¬¬[ä¸€äºŒä¸‰å››\d]+æ¡', snippet):
            checks.append("æ³•è§„âœ“")

        return " ".join(checks) if checks else "åŸºç¡€æ–‡æœ¬"

    def _calculate_quality_metrics(
        self, context: ResearchContext, config: dict
    ) -> QualityMetrics:
        """è®¡ç®—å®Œæ•´çš„è´¨é‡æŒ‡æ ‡"""
        metrics = config["quality_metrics"]

        # 1. ç›¸ä¼¼åº¦åˆ†é‡
        score_component = context.current_score * metrics["score_weight"]

        # 2. å†…å®¹ä¸°å¯Œåº¦
        richness = self._evaluate_content_richness(context.current_snippet)
        richness_component = richness * metrics["content_weight"]

        # 3. å»é‡åˆ†é‡
        if context.search_history:
            max_sim = max(
                self._compute_content_similarity(context.current_snippet, record.snippet)
                for record in context.search_history
            )
            dedup_threshold = metrics.get("dedup_threshold", 0.85)
            dedup_score = 0.0 if max_sim > dedup_threshold else 1.0
        else:
            dedup_score = 1.0

        dedup_component = dedup_score * metrics["dedup_weight"]
        duplication_percent = 1.0 - dedup_score

        # 4. ç´¯ç§¯è¯æ®åº¦
        all_snippets = [record.snippet for record in context.search_history] + [context.current_snippet]
        evidence_score = self._evaluate_cumulative_evidence(all_snippets)
        evidence_component = evidence_score * metrics["evidence_weight"]

        # ç»¼åˆè¯„åˆ†
        total_quality = score_component + richness_component + dedup_component + evidence_component

        # è´¨é‡ç­‰çº§
        if total_quality >= 0.7:
            quality_level = "ä¼˜ç§€"
            quality_stars = "â­â­â­"
        elif total_quality >= 0.5:
            quality_level = "ä¸­ç­‰"
            quality_stars = "â­â­"
        else:
            quality_level = "è¾ƒå·®"
            quality_stars = "â­"

        # è¶‹åŠ¿æŒ‡ç¤ºå™¨
        trend_indicator = self._calculate_trend(context.current_score, context.search_history)

        # å†…å®¹ç‰¹å¾
        has_numbers = bool(re.search(r'\d+', context.current_snippet))
        has_punctuation = bool(re.search(r'[ï¼š:ã€,ï¼Œ]', context.current_snippet))
        has_citation = bool(re.search(r'[æ¡ä¾‹]{2}|ç¬¬[ä¸€äºŒä¸‰å››\d]+æ¡', context.current_snippet))

        # è¯æ®è¦†ç›–åº¦
        coverage_areas = self._calculate_coverage(all_snippets)
        sufficiency_percent, _ = self._calculate_sufficiency(coverage_areas)

        return QualityMetrics(
            score_component=score_component,
            richness_component=richness_component,
            dedup_component=dedup_component,
            evidence_component=evidence_component,
            total_quality=total_quality,
            quality_level=quality_level,
            quality_stars=quality_stars,
            trend_indicator=trend_indicator,
            has_numbers=has_numbers,
            has_punctuation=has_punctuation,
            has_citation=has_citation,
            coverage_areas=coverage_areas,
            sufficiency_percent=sufficiency_percent,
            duplication_percent=duplication_percent
        )

    def _build_decision_prompt(
        self, context: ResearchContext, metrics: QualityMetrics
    ) -> str:
        """æ„å»º AI å†³ç­– Prompt"""
        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapter_title_short = context.chapter_title[:20] + "..." if len(context.chapter_title) > 20 else context.chapter_title

        # æ„å»ºæ£€ç´¢å†å²è¡¨æ ¼
        history_table = self._build_history_table(context.search_history)

        # å‡†å¤‡å½“å‰æ£€ç´¢ä¿¡æ¯
        current_query_short = context.current_query[:20] + "..." if len(context.current_query) > 20 else context.current_query
        current_snippet_preview = context.current_snippet[:30] + "..." if len(context.current_snippet) > 30 else context.current_snippet
        feature_checklist = self._build_feature_checklist(context.current_snippet)
        content_length = len(context.current_snippet)

        # æ„å»ºè¯æ®å……åˆ†æ€§åˆ†æ
        coverage_checklist = self._build_coverage_checklist(metrics.coverage_areas)
        sufficiency_percent, sufficiency_level = self._calculate_sufficiency(metrics.coverage_areas)
        evidence_count = len(context.search_history) + 1  # åŒ…æ‹¬å½“å‰
        total_chars = sum(len(r.snippet) for r in context.search_history) + len(context.current_snippet)

        # æ„å»º Prompt
        prompt = f"""ä½ æ˜¯ã€æ£€ç´¢å†³ç­–åŠ©æ‰‹ã€‘ã€‚åˆ¤æ–­æ˜¯å¦ç»§ç»­æ£€ç´¢çŸ¥è¯†åº“ã€‚

ã€å½“å‰çŠ¶æ€ã€‘
- ç« èŠ‚: ç¬¬{context.chapter_index}ç« "{chapter_title_short}" (å…±{context.total_chapters}ç« )
- è½®æ¬¡: ç¬¬{context.current_round}è½® / æœ€å°{context.min_rounds}è½® / æœ€å¤§{context.max_rounds}è½®
- æ¨¡å¼: {context.mode}

ã€æ£€ç´¢å†å²ã€‘
{history_table}

ã€å½“å‰æ£€ç´¢ã€‘ç¬¬{context.current_round}è½®
- å…³é”®è¯: "{current_query_short}"
- ç›¸ä¼¼åº¦: {context.current_score:.2f} ({metrics.quality_level}{metrics.trend_indicator})
- å†…å®¹: "{current_snippet_preview}"
- é•¿åº¦: {content_length}å­—
- å«: {feature_checklist}
- è´¨é‡: {metrics.quality_stars}

ã€è¯æ®å……åˆ†æ€§ã€‘
å·²æ”¶é›†{evidence_count}æ¡è¯æ® (çº¦{total_chars}å­—)
è¦†ç›–: {coverage_checklist}
é‡å¤åº¦: {metrics.duplication_percent:.0%}
å……åˆ†æ€§: {sufficiency_percent:.0%} ({sufficiency_level})

ã€å†³ç­–æ ‡å‡†ã€‘
âœ… åœæ­¢æ£€ç´¢: å……åˆ†æ€§â‰¥70% æˆ– (è¾¾åˆ°æœ€å¤§è½®æ•°) æˆ– (è¿ç»­è´¨é‡<0.5ä¸”é‡å¤åº¦>30%)
âŒ ç»§ç»­æ£€ç´¢: å……åˆ†æ€§<50% æˆ– è´¨é‡è¯„åˆ†â‰¥0.7ä¸”æœ‰æ˜æ˜¾æå‡è¶‹åŠ¿

è¿”å›JSON:
{{
  "decision": "continue" | "stop",
  "confidence": 0.0-1.0,
  "reason": "ç®€çŸ­ç†ç”± (20-30å­—)",
  "missing_aspects": ["ç¼ºå¤±æ–¹é¢1", "ç¼ºå¤±æ–¹é¢2"]
}}"""
        return prompt

    async def _ask_llm_for_decision(self, prompt: str) -> dict:
        """è°ƒç”¨ LLM è¿›è¡Œå†³ç­–"""
        try:
            response = await self.llm.ainvoke([
                SystemMessage(content="ä½ æ˜¯æ£€ç´¢å†³ç­–åŠ©æ‰‹ï¼Œè¿”å›çº¯JSONï¼Œä¸è¦å…¶ä»–æ ¼å¼ã€‚"),
                HumanMessage(content=prompt)
            ])

            content = response.content.strip()

            # å°è¯•æå– JSONï¼ˆå¤„ç† markdown ä»£ç å—æ ¼å¼ï¼‰
            json_str = content

            # å¦‚æœå“åº”åŒ…å« markdown ä»£ç å—ï¼Œæå–å…¶ä¸­çš„ JSON
            if "```" in content:
                import re
                json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # å°è¯•ç›´æ¥åŒ¹é… JSON å¯¹è±¡
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)

            # è§£æ JSON
            decision = json.loads(json_str)
            return {
                "decision": decision.get("decision", "continue"),
                "confidence": decision.get("confidence", 0.5),
                "reason": decision.get("reason", ""),
                "missing_aspects": decision.get("missing_aspects", [])
            }
        except json.JSONDecodeError as e:
            print(f"âš ï¸ AI å“åº” JSON è§£æå¤±è´¥: {e}")
            print(f"   åŸå§‹å“åº”: {response.content[:200]}")
            return {
                "decision": "continue",
                "confidence": 0.0,
                "reason": "AI å“åº”è§£æå¤±è´¥ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥",
                "missing_aspects": []
            }
        except Exception as e:
            print(f"âš ï¸ AI å†³ç­–è°ƒç”¨å¤±è´¥: {e}")
            return {
                "decision": "continue",
                "confidence": 0.0,
                "reason": f"AI è°ƒç”¨å¼‚å¸¸: {str(e)[:30]}",
                "missing_aspects": []
            }

    async def _should_continue_with_ai(
        self, context: ResearchContext, config: dict
    ) -> Tuple[bool, str, str]:
        """
        ä½¿ç”¨ AI å†³ç­–æ˜¯å¦ç»§ç»­æ£€ç´¢ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰

        Returns:
            (should_continue, reason, source)
            source: "ai" æˆ– "rule" (è¡¨ç¤ºé™çº§åˆ°è§„åˆ™)
        """
        try:
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            metrics = self._calculate_quality_metrics(context, config)

            # æ„å»º Prompt
            prompt = self._build_decision_prompt(context, metrics)

            # è°ƒç”¨ AI å†³ç­–
            decision_result = await self._ask_llm_for_decision(prompt)

            should_continue = decision_result["decision"] == "continue"
            reason = decision_result["reason"]

            return should_continue, reason, "ai"

        except Exception as e:
            # é™çº§åˆ°è§„åˆ™å†³ç­–
            print(f"âš ï¸ AI å†³ç­–å¤±è´¥: {e}, é™çº§åˆ°è§„åˆ™å†³ç­–")

            should_continue, reason = self._should_continue_research(
                current_round=context.current_round,
                snippet=context.current_snippet,
                score=context.current_score,
                section_notes=[r.snippet for r in context.search_history],
                mode=context.mode,
                config=config
            )

            return should_continue, reason + " (è§„åˆ™é™çº§)", "rule"

    async def generate_stream(self, input_text: str, language: str = "zh") -> AsyncGenerator[str, None]:
        """
        æ ¸å¿ƒç”Ÿæˆæµ
        """
        # 0. ç«‹å³æ¡æ‰‹
        engine_start = self._get_ui_text("engine_start", language)
        yield self._sse("thought", f"ğŸš€ {engine_start}")
        await asyncio.sleep(0.1)

        # 1. è·¯ç”±åˆ¤æ–­
        mode = self._detect_mode(input_text)
        
        if mode == "CUSTOMS":
            active_sop = self.sop_customs
            role_desc = self._get_ui_text("role_customs", language)
            task_desc = self._get_ui_text("task_customs", language)
            yield self._sse("thought", f"ğŸ” {self._get_ui_text('audit_mode', language)}")
        else:
            active_sop = self.sop_research
            role_desc = self._get_ui_text("role_research", language)
            task_desc = self._get_ui_text("task_research", language)
            yield self._sse("thought", f"ğŸ§  {self._get_ui_text('research_mode', language)}")
        
        state = {
            "topic": input_text,
            "mode": mode,
            "toc": [],
            "notebook": [],
            "used_doc_hashes": set(), 
            "full_report_text": "",
        }

        try:
            # ==========================================
            # é˜¶æ®µ 1: åŠ¨æ€è§„åˆ’
            # ==========================================
            building_outline = self._get_ui_text("building_outline", language)
            yield self._sse("thought", f"{building_outline}[{role_desc}]è§†è§’æ„å»ºå¤§çº²...")

            # ç¡®ä¿è¿™é‡Œä¼ äº† 4 ä¸ªå‚æ•°ï¼ˆåŒ…æ‹¬ languageï¼‰
            toc_list = await self._generate_toc(input_text, mode, active_sop, language)

            state["toc"] = toc_list
            yield self._sse("toc", toc_list)

            # ==========================================
            # é˜¶æ®µ 2: ç« èŠ‚å¾ªç¯
            # ==========================================
            for i, section_title in enumerate(toc_list):
                is_last_chapter = (i == len(toc_list) - 1)
                yield self._sse("step_start", {"index": i, "title": section_title})

                section_search_history = []
                section_notes = []

                if is_last_chapter:
                    reviewing_full_text = self._get_ui_text("reviewing_full_text", language)
                    yield self._sse("thought", f"{reviewing_full_text}...")
                    await asyncio.sleep(1.0)
                else:
                    # åŠ è½½æ™ºèƒ½æ£€ç´¢é…ç½®
                    research_config = self._load_research_config()
                    max_possible_rounds = research_config["rules"][mode]["max_rounds"]

                    round_idx = 0
                    continue_research = True

                    while continue_research and round_idx < max_possible_rounds:
                        round_idx += 1
                        previous_context = state["full_report_text"][-800:] if state["full_report_text"] else "ï¼ˆé¦–ç« ï¼‰"

                        # æ”¹è¿›çš„æœç´¢ç­–ç•¥ï¼šç¡®ä¿æ¯è½®æœç´¢ä¸åŒè§’åº¦
                        if round_idx == 1:
                            # ç¬¬ä¸€è½®ï¼šä»ç« èŠ‚æ ‡é¢˜ç›´æ¥æå–å…³é”®è¯
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚è¯·ç”Ÿæˆä¸€ä¸ªç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ï¼Œç›´æ¥ä»ç« èŠ‚æ ‡é¢˜ä¸­æå–æ ¸å¿ƒæ¦‚å¿µã€‚"
                        elif round_idx == 2:
                            # ç¬¬äºŒè½®ï¼šä»ä¸åŒè§’åº¦è¡¥å……æœç´¢ï¼ˆé¿å…é‡å¤ï¼‰
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚\n"
                            if section_search_history:
                                strategy_prompt += f"å·²æœç´¢è¿‡ï¼š{section_search_history}ï¼ˆè¿™äº›è§’åº¦å·²è¦†ç›–ï¼‰ã€‚\n"
                            strategy_prompt += f"è¯·ä»**å®Œå…¨ä¸åŒ**çš„è§’åº¦ï¼ˆå¦‚ï¼šé£é™©ç‚¹ã€å®¡æ ¸æ–¹æ³•ã€å¸¸è§é—®é¢˜ã€ç›‘ç®¡è¦æ±‚ç­‰ï¼‰ç”Ÿæˆä¸€ä¸ªæ–°çš„ç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ã€‚å¿…é¡»ä¸å·²æœç´¢å…³é”®è¯ä¸åŒï¼"
                        else:
                            # ç¬¬ä¸‰è½®ï¼šæ·±åº¦å…³è”æœç´¢
                            strategy_prompt = f"ä½ æ˜¯ä¸€å{role_desc}ã€‚æ­£åœ¨æ’°å†™ï¼šã€Š{section_title}ã€‹ã€‚\n"
                            if section_search_history:
                                strategy_prompt += f"å·²æœç´¢è¿‡ï¼š{section_search_history}ã€‚\n"
                            strategy_prompt += f"è¯·ä»**æ·±å±‚å…³è”**è§’åº¦ï¼ˆå¦‚ï¼šæ³•å¾‹ä¾æ®ã€å¤„ç½šæ¡ˆä¾‹ã€æ“ä½œè§„ç¨‹ç­‰ï¼‰ç”Ÿæˆä¸€ä¸ªæ–°çš„ç®€çŸ­æœç´¢å…³é”®è¯(2-6å­—)ã€‚å¿…é¡»é¿å…é‡å¤ï¼"

                        try:
                            q_res = await self.llm.ainvoke([HumanMessage(content=strategy_prompt)])
                            query = q_res.content.strip().split('\n')[0].replace('"', '')
                            # ç¡®ä¿ä¸é‡å¤
                            if query in section_search_history:
                                query = f"{section_title.split(' ')[0]}æ£€æŸ¥" if round_idx == 2 else f"{section_title.split(' ')[0]}é£é™©"
                        except Exception:
                            query = self._get_ui_text("default_query", language)

                        section_search_history.append(query)
                        search_keyword = self._get_ui_text("search_keyword", language)
                        yield self._sse("thought", f"[Round {round_idx}] {search_keyword}ï¼š'{query}'")
                        yield self._sse("rag_search", {"query": query})

                        snippet = "ï¼ˆæ— æœ¬åœ°ä¾æ®ï¼‰"
                        score = 0.0
                        filename = "System"

                        if self.kb:
                            try:
                                # å®‰å…¨è°ƒç”¨ï¼Œé˜²æ­¢æ–¹æ³•ä¸å­˜åœ¨
                                search_func = getattr(self.kb, "search_with_score", None)
                                if search_func:
                                    results = await asyncio.wait_for(search_func(query, k=3), timeout=10.0)
                                    if results:
                                        doc, similarity = results[0]
                                        snippet = doc.page_content

                                        # ğŸ”¥ æ–°å¢ï¼šä» metadata æå–æ–‡ä»¶åå¹¶éªŒè¯
                                        raw_filename = Path(doc.metadata.get("source", "unknown")).name

                                        # éªŒè¯æ–‡ä»¶åæ˜¯å¦ç¡®å®å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•ä¿®å¤
                                        filename = self._validate_and_fix_filename(raw_filename)

                                        score = similarity
                            except asyncio.TimeoutError:
                                pass # è¶…æ—¶å¿½ç•¥
                            except Exception as e:
                                print(f"æ£€ç´¢å¼‚å¸¸: {e}")

                        # ğŸ”¥ æ”¹è¿›ï¼šè¿”å›å®Œæ•´çš„ RAG åŒ¹é…ç‰‡æ®µï¼ˆè€Œä¸æ˜¯æˆªæ–­ï¼‰
                        # FAISS è¿”å›çš„ page_content å·²ç»æ˜¯ä¸€ä¸ª chunkï¼ˆçº¦1500å­—ç¬¦ï¼‰
                        # è¿™äº›å†…å®¹æ˜¯ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„éƒ¨åˆ†ï¼Œåº”è¯¥å®Œæ•´å±•ç¤º

                        # è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹å®é™…å‘é€çš„å†…å®¹
                        print(f"\nğŸ” [RAG_DEBUG] æŸ¥è¯¢: {query}")
                        print(f"ğŸ“„ [RAG_DEBUG] æ–‡ä»¶: {filename}")
                        print(f"ğŸ“ [RAG_DEBUG] snippet é•¿åº¦: {len(snippet)} å­—ç¬¦")
                        print(f"ğŸ“ [RAG_DEBUG] snippet å†…å®¹ï¼ˆå‰200å­—ï¼‰:")
                        print(snippet[:200])
                        print(f"ğŸ“ [RAG_DEBUG] snippet å†…å®¹ï¼ˆå200å­—ï¼‰:")
                        print(snippet[-200:] if len(snippet) > 200 else snippet)
                        print("-" * 80)

                        yield self._sse("rag_result", {
                            "filename": filename,
                            "score": float(score),
                            "snippet": snippet  # å®Œæ•´çš„ chunkï¼Œä¸æˆªæ–­
                        })
                        section_notes.append(f"å…³é”®è¯[{query}] -> {snippet[:200]}...")
                        state["notebook"].append(f"å…³é”®è¯[{query}] -> {snippet[:200]}...")

                        yield self._sse("take_note", {"content": f"{query}: {snippet[:20]}..."})

                        # ğŸ”¥ AI å†³ç­–ç³»ç»Ÿï¼šæ„å»ºæ£€ç´¢ä¸Šä¸‹æ–‡
                        # æ„å»º SearchRecord åˆ—è¡¨
                        search_records = []
                        for hist_round, hist_query in enumerate(section_search_history, 1):
                            # ä» section_notes ä¸­æå–å¯¹åº”çš„ snippet
                            hist_note = f"å…³é”®è¯[{hist_query}] ->"
                            for note in section_notes:
                                if note.startswith(hist_note):
                                    hist_snippet = note.replace(hist_note, "")
                                    # ä» state["notebook"] ä¸­æ‰¾å¯¹åº”çš„ score
                                    # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨ä¼°ç®—çš„ç›¸ä¼¼åº¦
                                    hist_score = score if hist_round == round_idx else 0.65
                                    search_records.append(SearchRecord(
                                        round=hist_round,
                                        query=hist_query,
                                        snippet=hist_snippet,
                                        score=hist_score
                                    ))
                                    break

                        # æ„å»ºå½“å‰æ£€ç´¢çš„ SearchRecordï¼ˆä¸åŒ…æ‹¬åœ¨ search_records ä¸­ï¼‰
                        current_record = SearchRecord(
                            round=round_idx,
                            query=query,
                            snippet=snippet,
                            score=score
                        )

                        # æ„å»º ResearchContext
                        context = ResearchContext(
                            chapter_index=i + 1,
                            chapter_title=section_title,
                            total_chapters=len(toc_list),
                            current_round=round_idx,
                            min_rounds=research_config["rules"][mode]["min_rounds"],
                            max_rounds=research_config["rules"][mode]["max_rounds"],
                            mode=mode,
                            search_history=search_records,
                            current_query=query,
                            current_snippet=snippet,
                            current_score=score
                        )

                        # ğŸ”¥ è°ƒç”¨ AI å†³ç­–ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰
                        should_continue, reason, source = await self._should_continue_with_ai(
                            context=context,
                            config=research_config
                        )

                        # è®¡ç®—è´¨é‡æŒ‡æ ‡ç”¨äºå‰ç«¯å±•ç¤º
                        metrics = self._calculate_quality_metrics(context, research_config)

                        # å‘å‰ç«¯å‘é€å†³ç­–äº‹ä»¶ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å« source å’Œ confidenceï¼‰
                        yield self._sse("research_decision", {
                            "round": round_idx,
                            "decision": "continue" if should_continue else "stop",
                            "reason": reason,
                            "source": source,  # "ai" æˆ– "rule"
                            "confidence": 0.8 if source == "ai" else 1.0,  # ç®€åŒ–å¤„ç†
                            "metrics": {
                                "score": metrics.score_component / 0.4,  # åæ¨åŸå§‹åˆ†æ•°
                                "richness": metrics.richness_component / 0.3,
                                "dedup": metrics.dedup_component / 0.2,
                                "evidence": metrics.evidence_component / 0.1,
                                "total_quality": metrics.total_quality
                            }
                        })

                        continue_research = should_continue

                        if should_continue:
                            source_badge = "[AIå†³ç­–]" if source == "ai" else "[è§„åˆ™]"
                            yield self._sse("thought", f"[ç»§ç»­] {source_badge} {reason}")
                            await asyncio.sleep(0.3)
                        else:
                            source_badge = "[AIå†³ç­–]" if source == "ai" else "[è§„åˆ™]"
                            yield self._sse("thought", f"[åœæ­¢] {source_badge} {reason}")
                            await asyncio.sleep(0.5)

                # æ’°å†™æ­£æ–‡
                language_instruction = self._get_language_instruction(language)
                write_prompt = f"""
ä½ æ˜¯ä¸€å{role_desc}ã€‚è¯·æ’°å†™ã€Š{section_title}ã€‹ã€‚
ã€å‰æ–‡ã€‘...{state["full_report_text"][-1000:] if state["full_report_text"] else "æ— "}
ã€è¯æ®ã€‘{json.dumps(section_notes, ensure_ascii=False)}
ã€è¯­è¨€è¦æ±‚ã€‘{language_instruction}
ã€æŒ‡ä»¤ã€‘ç›´æ¥è¾“å‡ºMarkdownæ­£æ–‡ï¼Œä¸è¦é‡å¤æ ‡é¢˜ã€‚
"""
                async for chunk in self.llm.astream([HumanMessage(content=write_prompt)]):
                    if chunk.content:
                        yield self._sse("report_chunk", chunk.content)
                        state["full_report_text"] += chunk.content
                
                state["full_report_text"] += "\n\n"
                yield self._sse("step_done", {"index": i})

            yield self._sse("done", {})

        except Exception as e:
            # æ•æ‰ä»»ä½•é”™è¯¯å¹¶å‘é€ç»™å‰ç«¯
            yield self._sse("error", str(e))

    async def _generate_toc(self, topic: str, mode: str, sop: str, language: str = "zh") -> List[str]:
        """åŒæ¨¡ç›®å½•ç”Ÿæˆå™¨"""
        if mode == "CUSTOMS":
            advice = "å»ºè®®åŒ…å«ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸æ˜¯ä¸€å®šè¦åŒ…å«è¿™äº›ï¼Œä½ éœ€è¦æ ¹æ®å…·ä½“å•æ®æ¥ç¡®å®šï¼‰ï¼š1.ç”³æŠ¥è¦ç´ å¤æ ¸ 2.ä»·æ ¼é€»è¾‘å®¡æŸ¥ 3.è´¸æ˜“ç®¡åˆ¶é£é™© 4.ç»¼åˆç»“è®º"
        else:
            advice = "å»ºè®®åŒ…å«ï¼ˆéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸æ˜¯ä¸€å®šè¦åŒ…å«è¿™äº›ï¼Œä½ éœ€è¦æ ¹æ®å…·ä½“å•æ®æ¥ç¡®å®šï¼‰ï¼š1.èƒŒæ™¯æ¦‚è¿° 2.æ ¸å¿ƒäº‹å®æ¢³ç† 3.æ·±åº¦å…³è”åˆ†æ 4.ç»“è®ºä¸å±•æœ›"

        language_instruction = self._get_language_instruction(language)
        prompt = f"""
ä½ æ˜¯ä¸€åé«˜çº§åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥è®¾è®¡ç›®å½•ã€‚
è¾“å…¥ï¼š{topic[:200]}
å»ºè®®ç»“æ„ï¼š{advice}
ã€è¯­è¨€è¦æ±‚ã€‘{language_instruction}
ã€ä¸¥æ ¼è¦æ±‚ã€‘
1. åªè¿”å›ä¸€ä¸ªçº¯ JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œå¦‚ ["1. æ ‡é¢˜A", "2. æ ‡é¢˜B"]
2. ç›®å½•æ ‡é¢˜ä½¿ç”¨å¯¹åº”çš„è¯­è¨€ï¼ˆä¸­æ–‡/è¶Šå—è¯­ï¼‰
3. ä¸è¦ Markdownï¼Œä¸è¦è§£é‡Šã€‚
"""
        try:
            res = await self.llm.ainvoke([HumanMessage(content=prompt)])
            text = re.sub(r'```json\s*|\s*```', '', res.content).strip()
            parsed = json.loads(text)
            clean_toc = []
            if isinstance(parsed, list):
                for idx, item in enumerate(parsed):
                    title = str(item) if not isinstance(item, dict) else str(list(item.values())[0])
                    clean_title = re.sub(r'^(\d+\.|Chapter\s*\d+|ç¬¬.+ç« )\s*', '', title).strip()
                    clean_toc.append(f"{idx + 1}. {clean_title}")
            return clean_toc if clean_toc else self._fallback_toc(mode, language)
        except Exception:
            return self._fallback_toc(mode, language)

    def _fallback_toc(self, mode, language: str = "zh"):
        if mode == "CUSTOMS":
            if language == "vi":
                return ["1. Kiá»ƒm tra cÃ¡c yáº¿u tá»‘ khai bÃ¡o", "2. PhÃ¢n tÃ­ch logic giÃ¡", "3. SÃ ng lá»c giáº¥y phÃ©p giÃ¡m sÃ¡t", "4. Káº¿t luáº­n vÃ  khuyáº¿n nghá»‹"]
            return ["1. ç”³æŠ¥è¦ç´ å¤æ ¸", "2. ä»·æ ¼é€»è¾‘åˆ†æ", "3. ç›‘ç®¡è¯ä»¶ç­›æŸ¥", "4. ç»“è®ºä¸å»ºè®®"]
        if language == "vi":
            return ["1. Tá»•ng quan vá» bá»‘i cáº£nh", "2. PhÃ¢n tÃ­ch cÃ¡c sá»± kiá»‡n cá»‘t lÃµi", "3. PhÃ¢n tÃ­ch liÃªn káº¿t sÃ¢u", "4. Káº¿t luáº­n vÃ  triá»ƒn vá»ng"]
        return ["1. èƒŒæ™¯æ¦‚è¿°", "2. æ ¸å¿ƒäº‹å®æ¢³ç†", "3. æ·±åº¦å…³è”åˆ†æ", "4. ç»“è®ºä¸å±•æœ›"]

    def _sse(self, type_str, payload):
        return f"data: {json.dumps({'type': type_str, 'payload': payload}, ensure_ascii=False)}\n\n"

    def _get_language_instruction(self, language: str) -> str:
        """ç”Ÿæˆè¯­è¨€è¾“å‡ºæŒ‡ä»¤"""
        # è¯­è¨€ä»£ç æ˜ å°„åˆ°å®é™…è¯­è¨€åç§°
        language_names = {
            "zh": "ç®€ä½“ä¸­æ–‡ (Chinese)",
            "vi": "Tiáº¿ng Viá»‡t (è¶Šå—è¯­)"
        }
        language_name = language_names.get(language, language_names["zh"])

        return f"""ã€é‡è¦è¯­è¨€è®¾ç½®ã€‘å½“å‰ç”¨æˆ·è®¾ç½®çš„è¯­è¨€æ˜¯ {language_name}ï¼Œè¯­è¨€ä»£ç ä¸º {language}ã€‚
ã€ä¸¥æ ¼è¦æ±‚ã€‘ä½ å¿…é¡»ä½¿ç”¨ {language_name} æ’°å†™æŠ¥å‘Šå†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€ç»“è®ºç­‰æ‰€æœ‰éƒ¨åˆ†ã€‚
æŠ¥å‘Šçš„æ‰€æœ‰è¾“å‡ºå¿…é¡»æ˜¯ {language_name}ï¼Œè¿™æ˜¯ç”¨æˆ·ç•Œé¢è¯­è¨€è®¾ç½®ï¼ŒæŠ¥å‘Šå°†ç›´æ¥æ˜¾ç¤ºç»™å‰ç«¯ç”¨æˆ·ã€‚"""

    def _get_ui_text(self, key: str, language: str = "zh") -> str:
        """è·å–UIæ˜¾ç¤ºæ–‡å­—"""
        ui_texts = {
            "zh": {
                "building_outline": "æ­£åœ¨åŸºäº",
                "reviewing_full_text": "æ­£åœ¨å›é¡¾å…¨æ–‡ï¼Œè¿›è¡Œé€»è¾‘æ”¶æŸä¸æœ€ç»ˆç ”åˆ¤",
                "search_keyword": "æ£€ç´¢å…³é”®è¯",
                "searching": "æ­£åœ¨æœç´¢",
                "writing": "æ­£åœ¨æ’°å†™",
                "default_query": "é€šç”¨é£é™©",
                "engine_start": "ç ”åˆ¤å¼•æ“å·²å¯åŠ¨ï¼Œæ­£åœ¨åˆ†æä»»åŠ¡æ„å›¾...",
                "role_customs": "æµ·å…³é«˜çº§æŸ¥éªŒä¸“å®¶",
                "task_customs": "è¿›è¡Œè¿›å‡ºå£åˆè§„æ€§å®¡æŸ¥",
                "audit_mode": "æ£€æµ‹åˆ°æŠ¥å…³å•æ®ï¼Œå·²åˆ‡æ¢è‡³ã€åˆè§„å®¡è®¡æ¨¡å¼ã€‘...",
                "role_research": "æ·±åº¦æ¡£æ¡ˆåˆ†æå¸ˆ",
                "task_research": "è¿›è¡Œæœ¬åœ°çŸ¥è¯†åº“æ·±åº¦æŒ–æ˜ä¸ç ”åˆ¤",
                "research_mode": "æ£€æµ‹åˆ°é€šç”¨é—®é¢˜ï¼Œå·²åˆ‡æ¢è‡³ã€æ·±åº¦ç ”åˆ¤æ¨¡å¼ã€‘..."
            },
            "vi": {
                "building_outline": "Äang xÃ¢y dá»±ng",
                "reviewing_full_text": "Äang xem láº¡i toÃ n vÄƒn, thá»±c hiá»‡n káº¿t luáº­n logic cuá»‘i cÃ¹ng",
                "search_keyword": "Tá»« khÃ³a tÃ¬m kiáº¿m",
                "searching": "Äang tÃ¬m kiáº¿m",
                "writing": "Äang viáº¿t",
                "default_query": "Rá»§i ro chung",
                "engine_start": "Äá»™ng cÆ¡ phÃ¢n tÃ­ch Ä‘Ã£ khá»Ÿi Ä‘á»™ng, Ä‘ang phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh nhiá»‡m vá»¥...",
                "role_customs": "ChuyÃªn gia kiá»ƒm tra háº£i quan cáº¥p cao",
                "task_customs": "Thá»±c hiá»‡n xem xÃ©t tuÃ¢n thá»§ xuáº¥t nháº­p kháº©u",
                "audit_mode": "PhÃ¡t hiá»‡n tá» khai háº£i quan, Ä‘Ã£ chuyá»ƒn sangã€Cháº¿ Ä‘á»™ kiá»ƒm toÃ¡n tuÃ¢n thá»§ã€‘...",
                "role_research": "ChuyÃªn gia phÃ¢n tÃ­ch há»“ sÆ¡ sÃ¢u",
                "task_research": "Thá»±c hiá»‡n khai thÃ¡c vÃ  nghiÃªn cá»©u sÃ¢u cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»‹a phÆ°Æ¡ng",
                "research_mode": "PhÃ¡t hiá»‡n váº¥n Ä‘á» chung, Ä‘Ã£ chuyá»ƒn sangã€Cháº¿ Ä‘á»™ nghiÃªn cá»©u sÃ¢uã€‘..."
            }
        }
        return ui_texts.get(language, ui_texts["zh"]).get(key, ui_texts["zh"][key])